{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 regularization\n",
    "\n",
    "The goal of this second notebook is to implement your own logistic regression classifier with L2 regularization. You will do the following:\n",
    "\n",
    " * Extract features from Amazon product reviews.\n",
    " * Convert an DataFrame into a NumPy array.\n",
    " * Write a function to compute the derivative of log likelihood function with an L2 penalty with respect to a single coefficient.\n",
    " * Implement gradient ascent with an L2 penalty.\n",
    " * Empirically explore how the L2 penalty can ameliorate overfitting.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process review dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we will use the same subset of the Amazon product review dataset that we used in Module 3 assignment. The subset was chosen to contain similar numbers of positive and negative reviews, as the original dataset consisted of mostly positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')\n",
    "products = products[:35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Tale of Baby\\'s Days with Peter Rabbit</td>\n",
       "      <td>Lovely book, it\\'s bound tightly so you may no...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>Perfect for new parents. We were able to keep ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>A friend of mine pinned this product on Pinter...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "6           A Tale of Baby\\'s Days with Peter Rabbit   \n",
       "7  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "8  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "9  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  \n",
       "5  When the Binky Fairy came to our house, we did...       5  \n",
       "6  Lovely book, it\\'s bound tightly so you may no...       4  \n",
       "7  Perfect for new parents. We were able to keep ...       5  \n",
       "8  A friend of mine pinned this product on Pinter...       5  \n",
       "9  This has been an easy way for my nanny to reco...       4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we did previously, we will work with a hand-curated list of important words extracted from the review data. We will also perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Compute word counts (only for the **important_words**)\n",
    "\n",
    "Refer to Module 3 assignment for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baby', 'one', 'great', 'love', 'use', 'would', 'like', 'easy', 'little', 'seat', 'old', 'well', 'get', 'also', 'really', 'son', 'time', 'bought', 'product', 'good', 'daughter', 'much', 'loves', 'stroller', 'put', 'months', 'car', 'still', 'back', 'used', 'recommend', 'first', 'even', 'perfect', 'nice', 'bag', 'two', 'using', 'got', 'fit', 'around', 'diaper', 'enough', 'month', 'price', 'go', 'could', 'soft', 'since', 'buy', 'room', 'works', 'made', 'child', 'keep', 'size', 'small', 'need', 'year', 'big', 'make', 'take', 'easily', 'think', 'crib', 'clean', 'way', 'quality', 'thing', 'better', 'without', 'set', 'new', 'every', 'cute', 'best', 'bottles', 'work', 'purchased', 'right', 'lot', 'side', 'happy', 'comfortable', 'toy', 'able', 'kids', 'bit', 'night', 'long', 'fits', 'see', 'us', 'another', 'play', 'day', 'money', 'monitor', 'tried', 'thought', 'never', 'item', 'hard', 'plastic', 'however', 'disappointed', 'reviews', 'something', 'going', 'pump', 'bottle', 'cup', 'waste', 'return', 'amazon', 'different', 'top', 'want', 'problem', 'know', 'water', 'try', 'received', 'sure', 'times', 'chair', 'find', 'hold', 'gate', 'open', 'bottom', 'away', 'actually', 'cheap', 'worked', 'getting', 'ordered', 'came', 'milk', 'bad', 'part', 'worth', 'found', 'cover', 'many', 'design', 'looking', 'weeks', 'say', 'wanted', 'look', 'place', 'purchase', 'looks', 'second', 'piece', 'box', 'pretty', 'trying', 'difficult', 'together', 'though', 'give', 'started', 'anything', 'last', 'company', 'come', 'returned', 'maybe', 'took', 'broke', 'makes', 'stay', 'instead', 'idea', 'head', 'said', 'less', 'went', 'working', 'high', 'unit', 'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won', 'tub', 'almost', 'either']\n"
     ]
    }
   ],
   "source": [
    "# The same feature processing (same as the previous assignments)\n",
    "# ---------------------------------------------------------------\n",
    "import json\n",
    "with open('important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]\n",
    "print(important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations and clean words\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return str(text).translate(string.punctuation) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation.\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "\n",
    "# Split out the words into individual columns\n",
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us take a look at what the dataset looks like (**Note:** This may take a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>would</th>\n",
       "      <th>...</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Tale of Baby\\'s Days with Peter Rabbit</td>\n",
       "      <td>Lovely book, it\\'s bound tightly so you may no...</td>\n",
       "      <td>4</td>\n",
       "      <td>Lovely book, it\\'s bound tightly so you may no...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>Perfect for new parents. We were able to keep ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Perfect for new parents. We were able to keep ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>A friend of mine pinned this product on Pinter...</td>\n",
       "      <td>5</td>\n",
       "      <td>A friend of mine pinned this product on Pinter...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This book is perfect!  I\\'m a first time new m...</td>\n",
       "      <td>5</td>\n",
       "      <td>This book is perfect!  I\\'m a first time new m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I originally just gave the nanny a pad of pape...</td>\n",
       "      <td>4</td>\n",
       "      <td>I originally just gave the nanny a pad of pape...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I thought keeping a simple handwritten journal...</td>\n",
       "      <td>3</td>\n",
       "      <td>I thought keeping a simple handwritten journal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nature\\'s Lullabies First Year Sticker Calendar</td>\n",
       "      <td>Space for monthly photos, info and a lot of us...</td>\n",
       "      <td>5</td>\n",
       "      <td>Space for monthly photos, info and a lot of us...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nature\\'s Lullabies First Year Sticker Calendar</td>\n",
       "      <td>I bought this calender for myself for my secon...</td>\n",
       "      <td>4</td>\n",
       "      <td>I bought this calender for myself for my secon...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nature\\'s Lullabies First Year Sticker Calendar</td>\n",
       "      <td>I love this little calender, you can keep trac...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this little calender, you can keep trac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>This was the only calender I could find for th...</td>\n",
       "      <td>5</td>\n",
       "      <td>This was the only calender I could find for th...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I completed a calendar for my son\\'s first yea...</td>\n",
       "      <td>4</td>\n",
       "      <td>I completed a calendar for my son\\'s first yea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>5</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I only purchased a second-year calendar for my...</td>\n",
       "      <td>2</td>\n",
       "      <td>I only purchased a second-year calendar for my...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I LOVE this calendar for recording events of m...</td>\n",
       "      <td>5</td>\n",
       "      <td>I LOVE this calendar for recording events of m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>Calendar is exactly as described, but I find t...</td>\n",
       "      <td>3</td>\n",
       "      <td>Calendar is exactly as described, but I find t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>Wife loves this calender. Comes with a lot of ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Wife loves this calender. Comes with a lot of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Baby\\'s First Journal - Green</td>\n",
       "      <td>Extremely useful! As a new mom, tired and inex...</td>\n",
       "      <td>5</td>\n",
       "      <td>Extremely useful! As a new mom, tired and inex...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>My son loves peek a boo at this age of 9 month...</td>\n",
       "      <td>3</td>\n",
       "      <td>My son loves peek a boo at this age of 9 month...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby\\'s first and favorite books, and i...</td>\n",
       "      <td>4</td>\n",
       "      <td>One of baby\\'s first and favorite books, and i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>I like how the book has a hook to attach it to...</td>\n",
       "      <td>5</td>\n",
       "      <td>I like how the book has a hook to attach it to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34970</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>This is a tether and so much more. I love that...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a tether and so much more. I love that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34971</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>the giraffe is very very smelly. i\\'ve been ai...</td>\n",
       "      <td>1</td>\n",
       "      <td>the giraffe is very very smelly. i\\'ve been ai...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34972</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>Seems a bit silly to me, but this giraffe actu...</td>\n",
       "      <td>5</td>\n",
       "      <td>Seems a bit silly to me, but this giraffe actu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34973</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I had a Sophie I had forgotten I bought.  Also...</td>\n",
       "      <td>1</td>\n",
       "      <td>I had a Sophie I had forgotten I bought.  Also...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34974</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I bought Sophie as a teething toy after readin...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought Sophie as a teething toy after readin...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34975</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>My 8 week old LOVES Sophie. The rubber feels s...</td>\n",
       "      <td>5</td>\n",
       "      <td>My 8 week old LOVES Sophie. The rubber feels s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34976</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>This is the perfect toy for a new baby. Santa ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the perfect toy for a new baby. Santa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34977</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I didn\\'t realize how soft the material is and...</td>\n",
       "      <td>4</td>\n",
       "      <td>I didn\\'t realize how soft the material is and...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34978</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I seriously don\\'t know what all the fuss is a...</td>\n",
       "      <td>2</td>\n",
       "      <td>I seriously don\\'t know what all the fuss is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34979</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>We received the Sophie on a Wednesday and by M...</td>\n",
       "      <td>1</td>\n",
       "      <td>We received the Sophie on a Wednesday and by M...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34980</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>My daughter loves it! I have had no problems. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter loves it! I have had no problems. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34981</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>Before you buy an expensive teether like Sophi...</td>\n",
       "      <td>2</td>\n",
       "      <td>Before you buy an expensive teether like Sophi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34982</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I never got hang of it when I saw the price an...</td>\n",
       "      <td>5</td>\n",
       "      <td>I never got hang of it when I saw the price an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34983</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I bought this for my daughter when she was 9 m...</td>\n",
       "      <td>3</td>\n",
       "      <td>I bought this for my daughter when she was 9 m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34984</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>Not worth the $16-17 for my kid. She barely pl...</td>\n",
       "      <td>3</td>\n",
       "      <td>Not worth the $16-17 for my kid. She barely pl...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34985</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>Going by the Amazon reviews, there was too muc...</td>\n",
       "      <td>2</td>\n",
       "      <td>Going by the Amazon reviews, there was too muc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34986</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>The neck is just the right size for little han...</td>\n",
       "      <td>5</td>\n",
       "      <td>The neck is just the right size for little han...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34987</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>We received this as a gift.  Our baby loves to...</td>\n",
       "      <td>5</td>\n",
       "      <td>We received this as a gift.  Our baby loves to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34988</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>My little one does not like it. This product h...</td>\n",
       "      <td>3</td>\n",
       "      <td>My little one does not like it. This product h...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34989</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>Let me be the 1,3777th person to review Sophie...</td>\n",
       "      <td>5</td>\n",
       "      <td>Let me be the 1,3777th person to review Sophie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34990</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I purchased this for my grand-daughter for Chr...</td>\n",
       "      <td>5</td>\n",
       "      <td>I purchased this for my grand-daughter for Chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34991</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>We adore this little giraffe; it was the first...</td>\n",
       "      <td>5</td>\n",
       "      <td>We adore this little giraffe; it was the first...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34992</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>This is a no brainer... this toy is like baby ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a no brainer... this toy is like baby ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34993</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>An excellent toy for teething babies - it is s...</td>\n",
       "      <td>4</td>\n",
       "      <td>An excellent toy for teething babies - it is s...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34994</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>When I received this the paint was peeling off...</td>\n",
       "      <td>1</td>\n",
       "      <td>When I received this the paint was peeling off...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>Had one for my first two children but it had s...</td>\n",
       "      <td>5</td>\n",
       "      <td>Had one for my first two children but it had s...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>I purchased this teether for my daughter when ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I purchased this teether for my daughter when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>It makes happy squeaking sounds, is safe for b...</td>\n",
       "      <td>5</td>\n",
       "      <td>It makes happy squeaking sounds, is safe for b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>There is a reason there is so much hype surrou...</td>\n",
       "      <td>5</td>\n",
       "      <td>There is a reason there is so much hype surrou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>Vulli Sophie the Giraffe Teether</td>\n",
       "      <td>My baby loves this giraffe.  He loves to look ...</td>\n",
       "      <td>4</td>\n",
       "      <td>My baby loves this giraffe.  He loves to look ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows  198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "0                               Planetwise Flannel Wipes   \n",
       "1                                  Planetwise Wipe Pouch   \n",
       "2                    Annas Dream Full Quilt with 2 Shams   \n",
       "3      Stop Pacifier Sucking without tears with Thumb...   \n",
       "4      Stop Pacifier Sucking without tears with Thumb...   \n",
       "5      Stop Pacifier Sucking without tears with Thumb...   \n",
       "6               A Tale of Baby\\'s Days with Peter Rabbit   \n",
       "7      Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "8      Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "9      Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "10     Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "11     Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "12     Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "13     Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "14       Nature\\'s Lullabies First Year Sticker Calendar   \n",
       "15       Nature\\'s Lullabies First Year Sticker Calendar   \n",
       "16       Nature\\'s Lullabies First Year Sticker Calendar   \n",
       "17      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "18      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "19      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "20      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "21      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "22      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "23      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "24      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "25      Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "26                         Baby\\'s First Journal - Green   \n",
       "27                           Lamaze Peekaboo, I Love You   \n",
       "28                           Lamaze Peekaboo, I Love You   \n",
       "29                           Lamaze Peekaboo, I Love You   \n",
       "...                                                  ...   \n",
       "34970                   Vulli Sophie the Giraffe Teether   \n",
       "34971                   Vulli Sophie the Giraffe Teether   \n",
       "34972                   Vulli Sophie the Giraffe Teether   \n",
       "34973                   Vulli Sophie the Giraffe Teether   \n",
       "34974                   Vulli Sophie the Giraffe Teether   \n",
       "34975                   Vulli Sophie the Giraffe Teether   \n",
       "34976                   Vulli Sophie the Giraffe Teether   \n",
       "34977                   Vulli Sophie the Giraffe Teether   \n",
       "34978                   Vulli Sophie the Giraffe Teether   \n",
       "34979                   Vulli Sophie the Giraffe Teether   \n",
       "34980                   Vulli Sophie the Giraffe Teether   \n",
       "34981                   Vulli Sophie the Giraffe Teether   \n",
       "34982                   Vulli Sophie the Giraffe Teether   \n",
       "34983                   Vulli Sophie the Giraffe Teether   \n",
       "34984                   Vulli Sophie the Giraffe Teether   \n",
       "34985                   Vulli Sophie the Giraffe Teether   \n",
       "34986                   Vulli Sophie the Giraffe Teether   \n",
       "34987                   Vulli Sophie the Giraffe Teether   \n",
       "34988                   Vulli Sophie the Giraffe Teether   \n",
       "34989                   Vulli Sophie the Giraffe Teether   \n",
       "34990                   Vulli Sophie the Giraffe Teether   \n",
       "34991                   Vulli Sophie the Giraffe Teether   \n",
       "34992                   Vulli Sophie the Giraffe Teether   \n",
       "34993                   Vulli Sophie the Giraffe Teether   \n",
       "34994                   Vulli Sophie the Giraffe Teether   \n",
       "34995                   Vulli Sophie the Giraffe Teether   \n",
       "34996                   Vulli Sophie the Giraffe Teether   \n",
       "34997                   Vulli Sophie the Giraffe Teether   \n",
       "34998                   Vulli Sophie the Giraffe Teether   \n",
       "34999                   Vulli Sophie the Giraffe Teether   \n",
       "\n",
       "                                                  review  rating  \\\n",
       "0      These flannel wipes are OK, but in my opinion ...       3   \n",
       "1      it came early and was not disappointed. i love...       5   \n",
       "2      Very soft and comfortable and warmer than it l...       5   \n",
       "3      This is a product well worth the purchase.  I ...       5   \n",
       "4      All of my kids have cried non-stop when I trie...       5   \n",
       "5      When the Binky Fairy came to our house, we did...       5   \n",
       "6      Lovely book, it\\'s bound tightly so you may no...       4   \n",
       "7      Perfect for new parents. We were able to keep ...       5   \n",
       "8      A friend of mine pinned this product on Pinter...       5   \n",
       "9      This has been an easy way for my nanny to reco...       4   \n",
       "10     I love this journal and our nanny uses it ever...       4   \n",
       "11     This book is perfect!  I\\'m a first time new m...       5   \n",
       "12     I originally just gave the nanny a pad of pape...       4   \n",
       "13     I thought keeping a simple handwritten journal...       3   \n",
       "14     Space for monthly photos, info and a lot of us...       5   \n",
       "15     I bought this calender for myself for my secon...       4   \n",
       "16     I love this little calender, you can keep trac...       5   \n",
       "17     This was the only calender I could find for th...       5   \n",
       "18     I completed a calendar for my son\\'s first yea...       4   \n",
       "19     We wanted to get something to keep track of ou...       5   \n",
       "20     I had a hard time finding a second year calend...       5   \n",
       "21     I only purchased a second-year calendar for my...       2   \n",
       "22     I LOVE this calendar for recording events of m...       5   \n",
       "23     Calendar is exactly as described, but I find t...       3   \n",
       "24     Wife loves this calender. Comes with a lot of ...       5   \n",
       "25     My daughter had her 1st baby over a year ago. ...       5   \n",
       "26     Extremely useful! As a new mom, tired and inex...       5   \n",
       "27     My son loves peek a boo at this age of 9 month...       3   \n",
       "28     One of baby\\'s first and favorite books, and i...       4   \n",
       "29     I like how the book has a hook to attach it to...       5   \n",
       "...                                                  ...     ...   \n",
       "34970  This is a tether and so much more. I love that...       5   \n",
       "34971  the giraffe is very very smelly. i\\'ve been ai...       1   \n",
       "34972  Seems a bit silly to me, but this giraffe actu...       5   \n",
       "34973  I had a Sophie I had forgotten I bought.  Also...       1   \n",
       "34974  I bought Sophie as a teething toy after readin...       5   \n",
       "34975  My 8 week old LOVES Sophie. The rubber feels s...       5   \n",
       "34976  This is the perfect toy for a new baby. Santa ...       5   \n",
       "34977  I didn\\'t realize how soft the material is and...       4   \n",
       "34978  I seriously don\\'t know what all the fuss is a...       2   \n",
       "34979  We received the Sophie on a Wednesday and by M...       1   \n",
       "34980  My daughter loves it! I have had no problems. ...       5   \n",
       "34981  Before you buy an expensive teether like Sophi...       2   \n",
       "34982  I never got hang of it when I saw the price an...       5   \n",
       "34983  I bought this for my daughter when she was 9 m...       3   \n",
       "34984  Not worth the $16-17 for my kid. She barely pl...       3   \n",
       "34985  Going by the Amazon reviews, there was too muc...       2   \n",
       "34986  The neck is just the right size for little han...       5   \n",
       "34987  We received this as a gift.  Our baby loves to...       5   \n",
       "34988  My little one does not like it. This product h...       3   \n",
       "34989  Let me be the 1,3777th person to review Sophie...       5   \n",
       "34990  I purchased this for my grand-daughter for Chr...       5   \n",
       "34991  We adore this little giraffe; it was the first...       5   \n",
       "34992  This is a no brainer... this toy is like baby ...       5   \n",
       "34993  An excellent toy for teething babies - it is s...       4   \n",
       "34994  When I received this the paint was peeling off...       1   \n",
       "34995  Had one for my first two children but it had s...       5   \n",
       "34996  I purchased this teether for my daughter when ...       5   \n",
       "34997  It makes happy squeaking sounds, is safe for b...       5   \n",
       "34998  There is a reason there is so much hype surrou...       5   \n",
       "34999  My baby loves this giraffe.  He loves to look ...       4   \n",
       "\n",
       "                                            review_clean  baby  one  great  \\\n",
       "0      These flannel wipes are OK, but in my opinion ...     0    0      0   \n",
       "1      it came early and was not disappointed. i love...     0    0      0   \n",
       "2      Very soft and comfortable and warmer than it l...     0    0      0   \n",
       "3      This is a product well worth the purchase.  I ...     0    0      0   \n",
       "4      All of my kids have cried non-stop when I trie...     0    0      1   \n",
       "5      When the Binky Fairy came to our house, we did...     0    0      1   \n",
       "6      Lovely book, it\\'s bound tightly so you may no...     0    0      0   \n",
       "7      Perfect for new parents. We were able to keep ...     0    0      0   \n",
       "8      A friend of mine pinned this product on Pinter...     0    0      0   \n",
       "9      This has been an easy way for my nanny to reco...     2    1      0   \n",
       "10     I love this journal and our nanny uses it ever...     3    0      0   \n",
       "11     This book is perfect!  I\\'m a first time new m...     0    0      0   \n",
       "12     I originally just gave the nanny a pad of pape...     0    0      0   \n",
       "13     I thought keeping a simple handwritten journal...     0    0      0   \n",
       "14     Space for monthly photos, info and a lot of us...     0    0      0   \n",
       "15     I bought this calender for myself for my secon...     1    1      0   \n",
       "16     I love this little calender, you can keep trac...     0    0      0   \n",
       "17     This was the only calender I could find for th...     0    3      0   \n",
       "18     I completed a calendar for my son\\'s first yea...     0    0      0   \n",
       "19     We wanted to get something to keep track of ou...     0    0      0   \n",
       "20     I had a hard time finding a second year calend...     2    1      1   \n",
       "21     I only purchased a second-year calendar for my...     0    3      0   \n",
       "22     I LOVE this calendar for recording events of m...     1    0      0   \n",
       "23     Calendar is exactly as described, but I find t...     0    0      0   \n",
       "24     Wife loves this calender. Comes with a lot of ...     0    0      0   \n",
       "25     My daughter had her 1st baby over a year ago. ...     1    0      0   \n",
       "26     Extremely useful! As a new mom, tired and inex...     1    0      0   \n",
       "27     My son loves peek a boo at this age of 9 month...     0    0      0   \n",
       "28     One of baby\\'s first and favorite books, and i...     0    0      0   \n",
       "29     I like how the book has a hook to attach it to...     0    0      0   \n",
       "...                                                  ...   ...  ...    ...   \n",
       "34970  This is a tether and so much more. I love that...     0    0      0   \n",
       "34971  the giraffe is very very smelly. i\\'ve been ai...     3    0      0   \n",
       "34972  Seems a bit silly to me, but this giraffe actu...     0    0      0   \n",
       "34973  I had a Sophie I had forgotten I bought.  Also...     0    4      0   \n",
       "34974  I bought Sophie as a teething toy after readin...     2    0      1   \n",
       "34975  My 8 week old LOVES Sophie. The rubber feels s...     0    0      0   \n",
       "34976  This is the perfect toy for a new baby. Santa ...     0    0      0   \n",
       "34977  I didn\\'t realize how soft the material is and...     1    0      0   \n",
       "34978  I seriously don\\'t know what all the fuss is a...     0    0      0   \n",
       "34979  We received the Sophie on a Wednesday and by M...     0    0      0   \n",
       "34980  My daughter loves it! I have had no problems. ...     0    0      0   \n",
       "34981  Before you buy an expensive teether like Sophi...     2    1      0   \n",
       "34982  I never got hang of it when I saw the price an...     0    0      0   \n",
       "34983  I bought this for my daughter when she was 9 m...     0    0      0   \n",
       "34984  Not worth the $16-17 for my kid. She barely pl...     2    0      0   \n",
       "34985  Going by the Amazon reviews, there was too muc...     0    0      0   \n",
       "34986  The neck is just the right size for little han...     0    0      0   \n",
       "34987  We received this as a gift.  Our baby loves to...     1    1      0   \n",
       "34988  My little one does not like it. This product h...     0    1      0   \n",
       "34989  Let me be the 1,3777th person to review Sophie...     0    0      0   \n",
       "34990  I purchased this for my grand-daughter for Chr...     1    1      2   \n",
       "34991  We adore this little giraffe; it was the first...     0    0      0   \n",
       "34992  This is a no brainer... this toy is like baby ...     3    1      0   \n",
       "34993  An excellent toy for teething babies - it is s...     2    0      0   \n",
       "34994  When I received this the paint was peeling off...     0    0      1   \n",
       "34995  Had one for my first two children but it had s...     0    2      0   \n",
       "34996  I purchased this teether for my daughter when ...     0    0      0   \n",
       "34997  It makes happy squeaking sounds, is safe for b...     1    0      0   \n",
       "34998  There is a reason there is so much hype surrou...     0    0      1   \n",
       "34999  My baby loves this giraffe.  He loves to look ...     2    0      1   \n",
       "\n",
       "       love  use  would    ...      picture  completely  wish  buying  babies  \\\n",
       "0         0    1      0    ...            0           0     0       0       0   \n",
       "1         1    0      0    ...            0           0     0       0       0   \n",
       "2         0    0      0    ...            0           0     0       0       0   \n",
       "3         2    0      0    ...            0           0     0       0       0   \n",
       "4         0    0      0    ...            0           0     0       0       0   \n",
       "5         0    0      1    ...            0           0     0       0       0   \n",
       "6         0    0      0    ...            0           0     0       0       0   \n",
       "7         0    0      1    ...            0           0     0       0       0   \n",
       "8         0    0      0    ...            0           0     0       0       0   \n",
       "9         0    0      0    ...            0           0     0       0       0   \n",
       "10        2    2      0    ...            0           0     0       0       0   \n",
       "11        0    0      1    ...            0           0     0       0       0   \n",
       "12        0    2      2    ...            0           0     0       0       0   \n",
       "13        0    0      1    ...            0           0     0       0       0   \n",
       "14        0    0      0    ...            0           0     0       0       0   \n",
       "15        0    0      1    ...            0           0     0       0       0   \n",
       "16        1    0      0    ...            0           0     0       0       0   \n",
       "17        0    0      0    ...            0           0     0       0       0   \n",
       "18        0    0      0    ...            0           0     0       0       0   \n",
       "19        0    0      0    ...            0           0     0       0       0   \n",
       "20        0    0      0    ...            1           0     0       0       0   \n",
       "21        0    0      0    ...            0           0     0       0       0   \n",
       "22        0    0      0    ...            0           0     0       0       0   \n",
       "23        0    0      0    ...            0           0     0       0       0   \n",
       "24        0    1      0    ...            0           0     0       0       0   \n",
       "25        0    0      0    ...            0           0     0       0       0   \n",
       "26        0    0      0    ...            0           0     0       0       0   \n",
       "27        0    0      1    ...            0           0     0       0       0   \n",
       "28        0    0      0    ...            0           0     0       0       0   \n",
       "29        0    0      0    ...            0           0     0       0       0   \n",
       "...     ...  ...    ...    ...          ...         ...   ...     ...     ...   \n",
       "34970     1    0      0    ...            0           0     0       0       0   \n",
       "34971     0    0      2    ...            0           0     0       0       0   \n",
       "34972     0    0      0    ...            0           0     0       0       2   \n",
       "34973     0    0      0    ...            0           0     0       0       0   \n",
       "34974     0    0      0    ...            0           0     0       0       0   \n",
       "34975     0    0      0    ...            0           0     0       0       0   \n",
       "34976     0    0      0    ...            0           0     0       0       0   \n",
       "34977     1    0      1    ...            0           0     0       0       0   \n",
       "34978     0    0      0    ...            0           0     0       0       0   \n",
       "34979     0    1      0    ...            0           1     0       0       0   \n",
       "34980     0    0      1    ...            0           0     1       0       0   \n",
       "34981     0    0      0    ...            0           0     0       0       0   \n",
       "34982     0    0      0    ...            0           0     0       0       0   \n",
       "34983     0    1      0    ...            0           0     0       0       0   \n",
       "34984     0    0      0    ...            0           0     0       0       0   \n",
       "34985     0    0      0    ...            0           0     0       0       0   \n",
       "34986     0    0      0    ...            0           0     0       0       0   \n",
       "34987     0    0      0    ...            0           0     0       0       0   \n",
       "34988     0    0      0    ...            0           0     0       0       0   \n",
       "34989     0    0      0    ...            0           0     0       0       0   \n",
       "34990     0    0      1    ...            0           0     0       0       0   \n",
       "34991     0    0      0    ...            0           0     0       0       0   \n",
       "34992     1    0      0    ...            0           0     0       0       0   \n",
       "34993     0    0      0    ...            0           0     0       0       1   \n",
       "34994     0    0      2    ...            0           0     0       0       0   \n",
       "34995     2    0      0    ...            0           0     0       0       1   \n",
       "34996     0    0      0    ...            0           0     0       0       0   \n",
       "34997     0    0      0    ...            0           0     0       0       0   \n",
       "34998     0    0      1    ...            0           0     0       0       0   \n",
       "34999     0    0      0    ...            0           0     0       0       0   \n",
       "\n",
       "       won  tub  almost  either  sentiment  \n",
       "0        0    0       0       0         -1  \n",
       "1        0    0       0       0          1  \n",
       "2        0    0       0       0          1  \n",
       "3        0    0       0       0          1  \n",
       "4        0    0       0       0          1  \n",
       "5        0    0       0       0          1  \n",
       "6        0    0       0       0          1  \n",
       "7        0    0       0       0          1  \n",
       "8        0    0       0       0          1  \n",
       "9        0    0       0       0          1  \n",
       "10       0    0       0       0          1  \n",
       "11       0    0       0       0          1  \n",
       "12       0    0       0       0          1  \n",
       "13       0    0       0       0         -1  \n",
       "14       0    0       0       0          1  \n",
       "15       0    0       0       0          1  \n",
       "16       0    0       0       0          1  \n",
       "17       0    0       0       0          1  \n",
       "18       0    0       0       0          1  \n",
       "19       0    0       0       0          1  \n",
       "20       0    0       0       0          1  \n",
       "21       0    0       0       0         -1  \n",
       "22       0    0       0       1          1  \n",
       "23       0    0       0       0         -1  \n",
       "24       0    0       0       0          1  \n",
       "25       0    0       0       0          1  \n",
       "26       0    0       0       0          1  \n",
       "27       0    0       0       0         -1  \n",
       "28       0    0       0       0          1  \n",
       "29       0    0       0       0          1  \n",
       "...    ...  ...     ...     ...        ...  \n",
       "34970    0    0       0       0          1  \n",
       "34971    0    0       0       0         -1  \n",
       "34972    0    0       0       0          1  \n",
       "34973    0    0       0       0         -1  \n",
       "34974    0    0       0       0          1  \n",
       "34975    0    0       1       0          1  \n",
       "34976    0    0       0       0          1  \n",
       "34977    0    0       0       0          1  \n",
       "34978    0    0       0       0         -1  \n",
       "34979    0    0       1       0         -1  \n",
       "34980    0    0       0       0          1  \n",
       "34981    0    0       0       0         -1  \n",
       "34982    0    0       0       0          1  \n",
       "34983    0    0       0       0         -1  \n",
       "34984    0    0       0       0         -1  \n",
       "34985    0    0       0       0         -1  \n",
       "34986    0    0       0       0          1  \n",
       "34987    0    0       0       0          1  \n",
       "34988    0    0       0       0         -1  \n",
       "34989    0    0       0       0          1  \n",
       "34990    0    0       0       0          1  \n",
       "34991    0    0       0       0          1  \n",
       "34992    0    0       0       0          1  \n",
       "34993    0    0       0       0          1  \n",
       "34994    0    0       0       0         -1  \n",
       "34995    0    0       0       0          1  \n",
       "34996    0    0       0       0          1  \n",
       "34997    0    0       0       0          1  \n",
       "34998    0    0       1       0          1  \n",
       "34999    0    0       0       0          1  \n",
       "\n",
       "[35000 rows x 198 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda x: +1 if x>3 else -1)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation split\n",
    "\n",
    "We split the data into a train-validation split with 80% of the data in the training set and 20% of the data in the validation set. We use `seed=2` so that everyone gets the same result.\n",
    "\n",
    "**Note:** In previous assignments, we have called this a **train-test split**. However, the portion of data that we don't train on will be used to help **select model parameters**. Thus, this portion of data should be called a **validation set**. Recall that examining performance of various potential models (i.e. models with different parameters) should be on a validation set, while evaluation of selected model should always be on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set   : 28000 data points\n",
      "Validation set : 7000 data points\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train , x_validation, y_train, y_validation = train_test_split(products,products['sentiment'], test_size =.2, random_state=20)\n",
    "\n",
    "print ('Training set   : %d data points' % len(x_train) )\n",
    "print ('Validation set : %d data points' % len(x_validation) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert SFrame to NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Just like in the second assignment of the previous module, we provide you with a function that extracts columns from an SFrame and converts them into a NumPy array. Two arrays are returned: one representing features and another representing class labels. \n",
    "\n",
    "**Note:** The feature matrix includes an additional column 'intercept' filled with 1's to take account of the intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_numpy_data(data_frame, features, label):\n",
    "    data_frame['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    feature_matrix = data_frame[features]\n",
    "    label_array = data_frame[label]\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert both the training and validation sets into NumPy arrays.\n",
    "\n",
    "**Warning**: This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_train, sentiment_train = get_numpy_data(x_train, important_words, 'sentiment')\n",
    "feature_matrix_valid, sentiment_valid = get_numpy_data(x_validation, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are you running this notebook on an Amazon EC2 t2.micro instance?** (If you are using your own machine, please skip this section)\n",
    "\n",
    "It has been reported that t2.micro instances do not provide sufficient power to complete the conversion in acceptable amount of time. For interest of time, please refrain from running `get_numpy_data` function. Instead, download the [binary file](https://s3.amazonaws.com/static.dato.com/files/coursera/course-3/numpy-arrays/module-4-assignment-numpy-arrays.npz) containing the four NumPy arrays you'll need for the assignment. To load the arrays, run the following commands:\n",
    "```\n",
    "arrays = np.load('module-4-assignment-numpy-arrays.npz')\n",
    "feature_matrix_train, sentiment_train = arrays['feature_matrix_train'], arrays['sentiment_train']\n",
    "feature_matrix_valid, sentiment_valid = arrays['feature_matrix_valid'], arrays['sentiment_valid']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building on logistic regression with no L2 penalty assignment\n",
    "\n",
    "Let us now build on Module 3 assignment. Recall from lecture that the link function for logistic regression can be defined as:\n",
    "\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "\n",
    "where the feature vector $h(\\mathbf{x}_i)$ is given by the word counts of **important_words** in the review $\\mathbf{x}_i$. \n",
    "\n",
    "We will use the **same code** as in this past assignment to make probability predictions since this part is not affected by the L2 penalty.  (Only the way in which the coefficients are learned is affected by the addition of a regularization term.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    ## YOUR CODE HERE\n",
    "    score=np.dot(feature_matrix,coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    ## YOUR CODE HERE\n",
    "    predictions = 1/(1+np.exp(-score))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding  L2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now work on extending logistic regression with L2 regularization. As discussed in the lectures, the L2 regularization is particularly useful in preventing overfitting. In this assignment, we will explore L2 regularization in detail.\n",
    "\n",
    "Recall from lecture and the previous assignment that for logistic regression without an L2 penalty, the derivative of the log likelihood function is:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "** Adding L2 penalty to the derivative** \n",
    "\n",
    "It takes only a small modification to add a L2 penalty. All terms indicated in **red** refer to terms that were added due to an **L2 penalty**.\n",
    "\n",
    "* Recall from the lecture that the link function is still the sigmoid:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "* We add the L2 penalty term to the per-coefficient derivative of log likelihood:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$\n",
    "\n",
    "The **per-coefficient derivative for logistic regression with an L2 penalty** is as follows:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$\n",
    "and for the intercept term, we have\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_0} = \\sum_{i=1}^N h_0(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: As we did in the Regression course, we do not apply the L2 penalty on the intercept. A large intercept does not necessarily indicate overfitting because the intercept is not associated with any particular feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. Unlike its counterpart in the last assignment, the function accepts five arguments:\n",
    " * `errors` vector containing $(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w}))$ for all $i$\n",
    " * `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$\n",
    " * `coefficient` containing the current value of coefficient $w_j$.\n",
    " * `l2_penalty` representing the L2 penalty constant $\\lambda$\n",
    " * `feature_is_constant` telling whether the $j$-th feature is constant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant): \n",
    "    \n",
    "    # Compute the dot product of errors and feature\n",
    "    ## YOUR CODE HERE\n",
    "    derivative = np.dot(errors, feature)\n",
    "\n",
    "    # add L2 penalty term for any feature that isn't the intercept.\n",
    "    if not feature_is_constant: \n",
    "        ## YOUR CODE HERE\n",
    "        derivative -= 2*l2_penalty*coefficient\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** In the code above, was the intercept term regularized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the correctness of the gradient ascent algorithm, we provide a function for computing log likelihood (which we recall from the last assignment was a topic detailed in an advanced optional video, and used here for its numerical stability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    logex = np.log(1. + np.exp(-scores))\n",
    "    lp = np.sum((indicator-1)*scores - logex) - l2_penalty*np.sum(coefficients**2)\n",
    "    \n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** Does the term with L2 regularization increase or decrease $\\ell\\ell(\\mathbf{w})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression function looks almost like the one in the last assignment, with a minor modification to account for the L2 penalty.  Fill in the code below to complete this modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    \n",
    "    for itr in range(max_iter):\n",
    "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
    "        ## YOUR CODE HERE\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        for j in range(len(coefficients)): # loop over each coefficient\n",
    "            is_intercept = (j == 0)\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            ## YOUR CODE HERE\n",
    "            derivative = feature_derivative_with_L2(errors, feature_matrix.iloc[:,j], coefficients[j], l2_penalty, is_intercept)\n",
    "\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            ## YOUR CODE HERE\n",
    "            coefficients[j] += step_size * derivative\n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
    "            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp) )\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore effects of L2 regularization\n",
    "\n",
    "Now that we have written up all the pieces needed for regularized logistic regression, let's explore the benefits of using **L2 regularization** in analyzing sentiment for product reviews. **As iterations pass, the log likelihood should increase**.\n",
    "\n",
    "Below, we train models with increasing amounts of regularization, starting with no L2 penalty, which is equivalent to our previous logistic regression implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -13558.23805233\n",
      "iteration   1: log likelihood of observed labels = -13303.64666106\n",
      "iteration   2: log likelihood of observed labels = -13089.75518353\n",
      "iteration   3: log likelihood of observed labels = -12908.86324459\n",
      "iteration   4: log likelihood of observed labels = -12754.76919537\n",
      "iteration   5: log likelihood of observed labels = -12622.51250681\n",
      "iteration   6: log likelihood of observed labels = -12508.13120751\n",
      "iteration   7: log likelihood of observed labels = -12408.45553189\n",
      "iteration   8: log likelihood of observed labels = -12320.94069373\n",
      "iteration   9: log likelihood of observed labels = -12243.53458226\n",
      "iteration  10: log likelihood of observed labels = -12174.57426379\n",
      "iteration  11: log likelihood of observed labels = -12112.70535780\n",
      "iteration  12: log likelihood of observed labels = -12056.81923765\n",
      "iteration  13: log likelihood of observed labels = -12006.00399983\n",
      "iteration  14: log likelihood of observed labels = -11959.50603715\n",
      "iteration  15: log likelihood of observed labels = -11916.69978283\n",
      "iteration  20: log likelihood of observed labels = -11742.46969183\n",
      "iteration  30: log likelihood of observed labels = -11498.56905574\n",
      "iteration  40: log likelihood of observed labels = -11313.72286603\n",
      "iteration  50: log likelihood of observed labels = -11157.96137721\n",
      "iteration  60: log likelihood of observed labels = -11022.19327855\n",
      "iteration  70: log likelihood of observed labels = -10902.44999768\n",
      "iteration  80: log likelihood of observed labels = -10796.21108215\n",
      "iteration  90: log likelihood of observed labels = -10701.50282451\n",
      "iteration 100: log likelihood of observed labels = -10616.67007038\n",
      "iteration 200: log likelihood of observed labels = -10087.18604931\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 0\n",
    "coefficients_0_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                     initial_coefficients=np.zeros(194),\n",
    "                                                     step_size=5e-6, l2_penalty=0, max_iter=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -13558.24442330\n",
      "iteration   1: log likelihood of observed labels = -13303.67681624\n",
      "iteration   2: log likelihood of observed labels = -13089.82077042\n",
      "iteration   3: log likelihood of observed labels = -12908.97182705\n",
      "iteration   4: log likelihood of observed labels = -12754.92549141\n",
      "iteration   5: log likelihood of observed labels = -12622.71927281\n",
      "iteration   6: log likelihood of observed labels = -12508.38986178\n",
      "iteration   7: log likelihood of observed labels = -12408.76659228\n",
      "iteration   8: log likelihood of observed labels = -12321.30408460\n",
      "iteration   9: log likelihood of observed labels = -12243.94984986\n",
      "iteration  10: log likelihood of observed labels = -12175.04072738\n",
      "iteration  11: log likelihood of observed labels = -12113.22221557\n",
      "iteration  12: log likelihood of observed labels = -12057.38564043\n",
      "iteration  13: log likelihood of observed labels = -12006.61910201\n",
      "iteration  14: log likelihood of observed labels = -11960.16903125\n",
      "iteration  15: log likelihood of observed labels = -11917.40992223\n",
      "iteration  20: log likelihood of observed labels = -11743.40719608\n",
      "iteration  30: log likelihood of observed labels = -11499.95120686\n",
      "iteration  40: log likelihood of observed labels = -11315.57907549\n",
      "iteration  50: log likelihood of observed labels = -11160.33911328\n",
      "iteration  60: log likelihood of observed labels = -11025.13779666\n",
      "iteration  70: log likelihood of observed labels = -10905.99750044\n",
      "iteration  80: log likelihood of observed labels = -10800.38795103\n",
      "iteration  90: log likelihood of observed labels = -10706.32696921\n",
      "iteration 100: log likelihood of observed labels = -10622.15270843\n",
      "iteration 200: log likelihood of observed labels = -10099.21674913\n",
      "iteration 300: log likelihood of observed labels = -9832.12842766\n",
      "iteration 400: log likelihood of observed labels = -9660.85494252\n",
      "iteration 500: log likelihood of observed labels = -9539.14208087\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 4\n",
    "coefficients_4_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=4, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -13558.25397976\n",
      "iteration   1: log likelihood of observed labels = -13303.72204666\n",
      "iteration   2: log likelihood of observed labels = -13089.91914057\n",
      "iteration   3: log likelihood of observed labels = -12909.13467584\n",
      "iteration   4: log likelihood of observed labels = -12755.15988852\n",
      "iteration   5: log likelihood of observed labels = -12623.02934568\n",
      "iteration   6: log likelihood of observed labels = -12508.77773115\n",
      "iteration   7: log likelihood of observed labels = -12409.23302877\n",
      "iteration   8: log likelihood of observed labels = -12321.84896914\n",
      "iteration   9: log likelihood of observed labels = -12244.57249675\n",
      "iteration  10: log likelihood of observed labels = -12175.74011099\n",
      "iteration  11: log likelihood of observed labels = -12113.99712899\n",
      "iteration  12: log likelihood of observed labels = -12058.23480612\n",
      "iteration  13: log likelihood of observed labels = -12007.54124802\n",
      "iteration  14: log likelihood of observed labels = -11961.16294297\n",
      "iteration  15: log likelihood of observed labels = -11918.47447654\n",
      "iteration  20: log likelihood of observed labels = -11744.81237336\n",
      "iteration  30: log likelihood of observed labels = -11502.02221433\n",
      "iteration  40: log likelihood of observed labels = -11318.35944567\n",
      "iteration  50: log likelihood of observed labels = -11163.89922915\n",
      "iteration  60: log likelihood of observed labels = -11029.54456001\n",
      "iteration  70: log likelihood of observed labels = -10911.30414665\n",
      "iteration  80: log likelihood of observed labels = -10806.63294738\n",
      "iteration  90: log likelihood of observed labels = -10713.53606822\n",
      "iteration 100: log likelihood of observed labels = -10630.34163270\n",
      "iteration 200: log likelihood of observed labels = -10117.09193105\n",
      "iteration 300: log likelihood of observed labels = -9858.77157121\n",
      "iteration 400: log likelihood of observed labels = -9695.37330306\n",
      "iteration 500: log likelihood of observed labels = -9580.79026672\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 10\n",
    "coefficients_10_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=10, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -13558.39732663\n",
      "iteration   1: log likelihood of observed labels = -13304.40016608\n",
      "iteration   2: log likelihood of observed labels = -13091.39322936\n",
      "iteration   3: log likelihood of observed labels = -12911.57382604\n",
      "iteration   4: log likelihood of observed labels = -12758.66909811\n",
      "iteration   5: log likelihood of observed labels = -12627.66950281\n",
      "iteration   6: log likelihood of observed labels = -12514.57968737\n",
      "iteration   7: log likelihood of observed labels = -12416.20746411\n",
      "iteration   8: log likelihood of observed labels = -12329.99330197\n",
      "iteration   9: log likelihood of observed labels = -12253.87572543\n",
      "iteration  10: log likelihood of observed labels = -12186.18620553\n",
      "iteration  11: log likelihood of observed labels = -12125.56740167\n",
      "iteration  12: log likelihood of observed labels = -12070.90955934\n",
      "iteration  13: log likelihood of observed labels = -12021.30090784\n",
      "iteration  14: log likelihood of observed labels = -11975.98882497\n",
      "iteration  15: log likelihood of observed labels = -11934.34928798\n",
      "iteration  20: log likelihood of observed labels = -11765.73642867\n",
      "iteration  30: log likelihood of observed labels = -11532.77347525\n",
      "iteration  40: log likelihood of observed labels = -11359.51066204\n",
      "iteration  50: log likelihood of observed labels = -11216.39426892\n",
      "iteration  60: log likelihood of observed labels = -11094.25419044\n",
      "iteration  70: log likelihood of observed labels = -10988.88397796\n",
      "iteration  80: log likelihood of observed labels = -10897.51411119\n",
      "iteration  90: log likelihood of observed labels = -10817.96009195\n",
      "iteration 100: log likelihood of observed labels = -10748.40280184\n",
      "iteration 200: log likelihood of observed labels = -10363.02164131\n",
      "iteration 300: log likelihood of observed labels = -10209.11928684\n",
      "iteration 400: log likelihood of observed labels = -10130.20065721\n",
      "iteration 500: log likelihood of observed labels = -10084.71954157\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e2\n",
    "coefficients_1e2_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e2, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -13559.83079532\n",
      "iteration   1: log likelihood of observed labels = -13311.14671213\n",
      "iteration   2: log likelihood of observed labels = -13105.98440262\n",
      "iteration   3: log likelihood of observed labels = -12935.60089128\n",
      "iteration   4: log likelihood of observed labels = -12793.07835568\n",
      "iteration   5: log likelihood of observed labels = -12672.97029105\n",
      "iteration   6: log likelihood of observed labels = -12570.98908029\n",
      "iteration   7: log likelihood of observed labels = -12483.75045719\n",
      "iteration   8: log likelihood of observed labels = -12408.57207096\n",
      "iteration   9: log likelihood of observed labels = -12343.31745266\n",
      "iteration  10: log likelihood of observed labels = -12286.27602274\n",
      "iteration  11: log likelihood of observed labels = -12236.07095518\n",
      "iteration  12: log likelihood of observed labels = -12191.58830610\n",
      "iteration  13: log likelihood of observed labels = -12151.92229939\n",
      "iteration  14: log likelihood of observed labels = -12116.33288620\n",
      "iteration  15: log likelihood of observed labels = -12084.21265106\n",
      "iteration  20: log likelihood of observed labels = -11960.82336294\n",
      "iteration  30: log likelihood of observed labels = -11813.09776056\n",
      "iteration  40: log likelihood of observed labels = -11725.70156160\n",
      "iteration  50: log likelihood of observed labels = -11671.00105232\n",
      "iteration  60: log likelihood of observed labels = -11638.40246475\n",
      "iteration  70: log likelihood of observed labels = -11621.73246888\n",
      "iteration  80: log likelihood of observed labels = -11616.62864128\n",
      "iteration  90: log likelihood of observed labels = -11619.83952381\n",
      "iteration 100: log likelihood of observed labels = -11628.92331471\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e3\n",
    "coefficients_1e3_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e3, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -13717.51235170\n",
      "iteration   1: log likelihood of observed labels = -13771.91173726\n",
      "iteration   2: log likelihood of observed labels = -13920.59652428\n",
      "iteration   3: log likelihood of observed labels = -14155.76222881\n",
      "iteration   4: log likelihood of observed labels = -14471.17449458\n",
      "iteration   5: log likelihood of observed labels = -14860.87750092\n",
      "iteration   6: log likelihood of observed labels = -15319.26725474\n",
      "iteration   7: log likelihood of observed labels = -15841.06379278\n",
      "iteration   8: log likelihood of observed labels = -16421.29580252\n",
      "iteration   9: log likelihood of observed labels = -17055.28464819\n",
      "iteration  10: log likelihood of observed labels = -17738.62913591\n",
      "iteration  11: log likelihood of observed labels = -18467.19089193\n",
      "iteration  12: log likelihood of observed labels = -19237.08036364\n",
      "iteration  13: log likelihood of observed labels = -20044.64343602\n",
      "iteration  14: log likelihood of observed labels = -20886.44865432\n",
      "iteration  15: log likelihood of observed labels = -21759.27504075\n",
      "iteration  20: log likelihood of observed labels = -26489.30831829\n",
      "iteration  30: log likelihood of observed labels = -36907.44749326\n",
      "iteration  40: log likelihood of observed labels = -47410.66868285\n",
      "iteration  50: log likelihood of observed labels = -57233.44526108\n",
      "iteration  60: log likelihood of observed labels = -66052.09391022\n",
      "iteration  70: log likelihood of observed labels = -73776.69873048\n",
      "iteration  80: log likelihood of observed labels = -80436.50272652\n",
      "iteration  90: log likelihood of observed labels = -86117.06689944\n",
      "iteration 100: log likelihood of observed labels = -90926.12102131\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e5\n",
    "coefficients_1e5_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e5, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare coefficients\n",
    "\n",
    "We now compare the **coefficients** for each of the models that were trained above. We will create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
    "\n",
    "Below is a simple helper function that will help us create this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'word': ['(intercept)'] + important_words})\n",
    "def add_coefficients_to_table(coefficients, column_name):\n",
    "    table[column_name] = coefficients\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's run the function `add_coefficients_to_table` for each of the L2 penalty strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficients [L2=0]</th>\n",
       "      <th>coefficients [L2=4]</th>\n",
       "      <th>coefficients [L2=10]</th>\n",
       "      <th>coefficients [L2=1e2]</th>\n",
       "      <th>coefficients [L2=1e3]</th>\n",
       "      <th>coefficients [L2=1e5]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(intercept)</td>\n",
       "      <td>0.762657</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>0.856938</td>\n",
       "      <td>0.880735</td>\n",
       "      <td>0.852262</td>\n",
       "      <td>0.998794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baby</td>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.059369</td>\n",
       "      <td>0.054209</td>\n",
       "      <td>0.037056</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>0.037345</td>\n",
       "      <td>0.049853</td>\n",
       "      <td>0.049318</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.328113</td>\n",
       "      <td>0.451299</td>\n",
       "      <td>0.445919</td>\n",
       "      <td>0.377037</td>\n",
       "      <td>0.154786</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>0.468496</td>\n",
       "      <td>0.732949</td>\n",
       "      <td>0.723518</td>\n",
       "      <td>0.603417</td>\n",
       "      <td>0.219053</td>\n",
       "      <td>0.003136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>use</td>\n",
       "      <td>0.035381</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>would</td>\n",
       "      <td>-0.217820</td>\n",
       "      <td>-0.241985</td>\n",
       "      <td>-0.240310</td>\n",
       "      <td>-0.218540</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>-0.002730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>-0.017504</td>\n",
       "      <td>-0.041793</td>\n",
       "      <td>-0.041458</td>\n",
       "      <td>-0.037099</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>-0.000432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>easy</td>\n",
       "      <td>0.439957</td>\n",
       "      <td>0.649475</td>\n",
       "      <td>0.641557</td>\n",
       "      <td>0.540604</td>\n",
       "      <td>0.210677</td>\n",
       "      <td>0.003162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>little</td>\n",
       "      <td>0.228466</td>\n",
       "      <td>0.316214</td>\n",
       "      <td>0.312677</td>\n",
       "      <td>0.267211</td>\n",
       "      <td>0.112351</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seat</td>\n",
       "      <td>-0.059911</td>\n",
       "      <td>-0.110454</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>-0.088434</td>\n",
       "      <td>-0.020803</td>\n",
       "      <td>-0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>old</td>\n",
       "      <td>0.111582</td>\n",
       "      <td>0.115707</td>\n",
       "      <td>0.114545</td>\n",
       "      <td>0.099660</td>\n",
       "      <td>0.055971</td>\n",
       "      <td>0.000793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>well</td>\n",
       "      <td>0.115740</td>\n",
       "      <td>0.182109</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.147550</td>\n",
       "      <td>0.050551</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>get</td>\n",
       "      <td>-0.122042</td>\n",
       "      <td>-0.140108</td>\n",
       "      <td>-0.139075</td>\n",
       "      <td>-0.125660</td>\n",
       "      <td>-0.063849</td>\n",
       "      <td>-0.001466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>also</td>\n",
       "      <td>0.083136</td>\n",
       "      <td>0.108947</td>\n",
       "      <td>0.107847</td>\n",
       "      <td>0.093707</td>\n",
       "      <td>0.043484</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>really</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>-0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>son</td>\n",
       "      <td>0.081668</td>\n",
       "      <td>0.078104</td>\n",
       "      <td>0.077395</td>\n",
       "      <td>0.068282</td>\n",
       "      <td>0.041329</td>\n",
       "      <td>0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>-0.081738</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>-0.122271</td>\n",
       "      <td>-0.105208</td>\n",
       "      <td>-0.039179</td>\n",
       "      <td>-0.000768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bought</td>\n",
       "      <td>-0.010980</td>\n",
       "      <td>-0.063384</td>\n",
       "      <td>-0.062840</td>\n",
       "      <td>-0.055636</td>\n",
       "      <td>-0.009315</td>\n",
       "      <td>-0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>product</td>\n",
       "      <td>-0.134109</td>\n",
       "      <td>-0.238788</td>\n",
       "      <td>-0.236441</td>\n",
       "      <td>-0.205863</td>\n",
       "      <td>-0.071484</td>\n",
       "      <td>-0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>good</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>-0.020145</td>\n",
       "      <td>-0.020200</td>\n",
       "      <td>-0.020724</td>\n",
       "      <td>-0.003879</td>\n",
       "      <td>-0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>daughter</td>\n",
       "      <td>0.118447</td>\n",
       "      <td>0.138765</td>\n",
       "      <td>0.137185</td>\n",
       "      <td>0.117036</td>\n",
       "      <td>0.056511</td>\n",
       "      <td>0.000740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>much</td>\n",
       "      <td>-0.014771</td>\n",
       "      <td>-0.026415</td>\n",
       "      <td>-0.026315</td>\n",
       "      <td>-0.024957</td>\n",
       "      <td>-0.009324</td>\n",
       "      <td>-0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loves</td>\n",
       "      <td>0.357393</td>\n",
       "      <td>0.592302</td>\n",
       "      <td>0.584335</td>\n",
       "      <td>0.482765</td>\n",
       "      <td>0.163122</td>\n",
       "      <td>0.002210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stroller</td>\n",
       "      <td>-0.031619</td>\n",
       "      <td>-0.059117</td>\n",
       "      <td>-0.058204</td>\n",
       "      <td>-0.046538</td>\n",
       "      <td>-0.011110</td>\n",
       "      <td>-0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>put</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>months</td>\n",
       "      <td>0.038518</td>\n",
       "      <td>0.030986</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.028454</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>car</td>\n",
       "      <td>0.045315</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.079354</td>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>still</td>\n",
       "      <td>0.079155</td>\n",
       "      <td>0.125111</td>\n",
       "      <td>0.123584</td>\n",
       "      <td>0.103907</td>\n",
       "      <td>0.038186</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>back</td>\n",
       "      <td>-0.113292</td>\n",
       "      <td>-0.160572</td>\n",
       "      <td>-0.158816</td>\n",
       "      <td>-0.136305</td>\n",
       "      <td>-0.054362</td>\n",
       "      <td>-0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>started</td>\n",
       "      <td>-0.009859</td>\n",
       "      <td>-0.029606</td>\n",
       "      <td>-0.029225</td>\n",
       "      <td>-0.024301</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>-0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>anything</td>\n",
       "      <td>-0.020600</td>\n",
       "      <td>-0.040905</td>\n",
       "      <td>-0.040408</td>\n",
       "      <td>-0.033992</td>\n",
       "      <td>-0.009972</td>\n",
       "      <td>-0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>last</td>\n",
       "      <td>-0.022152</td>\n",
       "      <td>-0.046510</td>\n",
       "      <td>-0.045936</td>\n",
       "      <td>-0.038571</td>\n",
       "      <td>-0.010726</td>\n",
       "      <td>-0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>company</td>\n",
       "      <td>-0.060102</td>\n",
       "      <td>-0.121491</td>\n",
       "      <td>-0.119920</td>\n",
       "      <td>-0.099658</td>\n",
       "      <td>-0.028113</td>\n",
       "      <td>-0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>come</td>\n",
       "      <td>-0.006676</td>\n",
       "      <td>-0.013346</td>\n",
       "      <td>-0.013268</td>\n",
       "      <td>-0.012215</td>\n",
       "      <td>-0.004294</td>\n",
       "      <td>-0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>returned</td>\n",
       "      <td>-0.115256</td>\n",
       "      <td>-0.255389</td>\n",
       "      <td>-0.251925</td>\n",
       "      <td>-0.207194</td>\n",
       "      <td>-0.052394</td>\n",
       "      <td>-0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>maybe</td>\n",
       "      <td>-0.062900</td>\n",
       "      <td>-0.131173</td>\n",
       "      <td>-0.129368</td>\n",
       "      <td>-0.106139</td>\n",
       "      <td>-0.028238</td>\n",
       "      <td>-0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>took</td>\n",
       "      <td>-0.005707</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>-0.001401</td>\n",
       "      <td>-0.002572</td>\n",
       "      <td>-0.003503</td>\n",
       "      <td>-0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>broke</td>\n",
       "      <td>-0.072218</td>\n",
       "      <td>-0.161854</td>\n",
       "      <td>-0.159637</td>\n",
       "      <td>-0.131044</td>\n",
       "      <td>-0.032660</td>\n",
       "      <td>-0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>makes</td>\n",
       "      <td>0.047088</td>\n",
       "      <td>0.075098</td>\n",
       "      <td>0.074052</td>\n",
       "      <td>0.060706</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>stay</td>\n",
       "      <td>-0.030220</td>\n",
       "      <td>-0.071293</td>\n",
       "      <td>-0.070374</td>\n",
       "      <td>-0.058498</td>\n",
       "      <td>-0.014542</td>\n",
       "      <td>-0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>instead</td>\n",
       "      <td>-0.016242</td>\n",
       "      <td>-0.040411</td>\n",
       "      <td>-0.039845</td>\n",
       "      <td>-0.032551</td>\n",
       "      <td>-0.007271</td>\n",
       "      <td>-0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>idea</td>\n",
       "      <td>-0.067867</td>\n",
       "      <td>-0.152421</td>\n",
       "      <td>-0.150294</td>\n",
       "      <td>-0.122905</td>\n",
       "      <td>-0.030359</td>\n",
       "      <td>-0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>head</td>\n",
       "      <td>-0.034119</td>\n",
       "      <td>-0.070852</td>\n",
       "      <td>-0.069943</td>\n",
       "      <td>-0.058206</td>\n",
       "      <td>-0.015705</td>\n",
       "      <td>-0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>said</td>\n",
       "      <td>-0.034362</td>\n",
       "      <td>-0.058456</td>\n",
       "      <td>-0.057763</td>\n",
       "      <td>-0.048845</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>less</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>-0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>went</td>\n",
       "      <td>-0.045452</td>\n",
       "      <td>-0.081201</td>\n",
       "      <td>-0.080204</td>\n",
       "      <td>-0.067389</td>\n",
       "      <td>-0.021469</td>\n",
       "      <td>-0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>working</td>\n",
       "      <td>-0.030264</td>\n",
       "      <td>-0.067136</td>\n",
       "      <td>-0.066210</td>\n",
       "      <td>-0.054320</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>-0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>high</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.019207</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>unit</td>\n",
       "      <td>-0.055325</td>\n",
       "      <td>-0.107959</td>\n",
       "      <td>-0.106555</td>\n",
       "      <td>-0.088466</td>\n",
       "      <td>-0.025636</td>\n",
       "      <td>-0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>seems</td>\n",
       "      <td>-0.016585</td>\n",
       "      <td>-0.040065</td>\n",
       "      <td>-0.039560</td>\n",
       "      <td>-0.033053</td>\n",
       "      <td>-0.007993</td>\n",
       "      <td>-0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>picture</td>\n",
       "      <td>-0.031828</td>\n",
       "      <td>-0.064669</td>\n",
       "      <td>-0.063897</td>\n",
       "      <td>-0.053901</td>\n",
       "      <td>-0.015688</td>\n",
       "      <td>-0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>completely</td>\n",
       "      <td>-0.048952</td>\n",
       "      <td>-0.104243</td>\n",
       "      <td>-0.102837</td>\n",
       "      <td>-0.084717</td>\n",
       "      <td>-0.022232</td>\n",
       "      <td>-0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.025947</td>\n",
       "      <td>0.045034</td>\n",
       "      <td>0.044290</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>0.009898</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>buying</td>\n",
       "      <td>-0.036287</td>\n",
       "      <td>-0.083473</td>\n",
       "      <td>-0.082351</td>\n",
       "      <td>-0.067897</td>\n",
       "      <td>-0.016750</td>\n",
       "      <td>-0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>babies</td>\n",
       "      <td>0.016587</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>won</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tub</td>\n",
       "      <td>-0.084962</td>\n",
       "      <td>-0.144248</td>\n",
       "      <td>-0.142546</td>\n",
       "      <td>-0.120599</td>\n",
       "      <td>-0.038997</td>\n",
       "      <td>-0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>almost</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.040409</td>\n",
       "      <td>0.032966</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>either</td>\n",
       "      <td>-0.033165</td>\n",
       "      <td>-0.069721</td>\n",
       "      <td>-0.068757</td>\n",
       "      <td>-0.056373</td>\n",
       "      <td>-0.014782</td>\n",
       "      <td>-0.000207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficients [L2=0]  coefficients [L2=4]  \\\n",
       "0    (intercept)             0.762657             0.855204   \n",
       "1           baby             0.062333             0.059760   \n",
       "2            one             0.037345             0.049853   \n",
       "3          great             0.328113             0.451299   \n",
       "4           love             0.468496             0.732949   \n",
       "5            use             0.035381             0.014375   \n",
       "6          would            -0.217820            -0.241985   \n",
       "7           like            -0.017504            -0.041793   \n",
       "8           easy             0.439957             0.649475   \n",
       "9         little             0.228466             0.316214   \n",
       "10          seat            -0.059911            -0.110454   \n",
       "11           old             0.111582             0.115707   \n",
       "12          well             0.115740             0.182109   \n",
       "13           get            -0.122042            -0.140108   \n",
       "14          also             0.083136             0.108947   \n",
       "15        really             0.013597             0.003504   \n",
       "16           son             0.081668             0.078104   \n",
       "17          time            -0.081738            -0.123595   \n",
       "18        bought            -0.010980            -0.063384   \n",
       "19       product            -0.134109            -0.238788   \n",
       "20          good             0.002666            -0.020145   \n",
       "21      daughter             0.118447             0.138765   \n",
       "22          much            -0.014771            -0.026415   \n",
       "23         loves             0.357393             0.592302   \n",
       "24      stroller            -0.031619            -0.059117   \n",
       "25           put             0.016096             0.009267   \n",
       "26        months             0.038518             0.030986   \n",
       "27           car             0.045315             0.080537   \n",
       "28         still             0.079155             0.125111   \n",
       "29          back            -0.113292            -0.160572   \n",
       "..           ...                  ...                  ...   \n",
       "164      started            -0.009859            -0.029606   \n",
       "165     anything            -0.020600            -0.040905   \n",
       "166         last            -0.022152            -0.046510   \n",
       "167      company            -0.060102            -0.121491   \n",
       "168         come            -0.006676            -0.013346   \n",
       "169     returned            -0.115256            -0.255389   \n",
       "170        maybe            -0.062900            -0.131173   \n",
       "171         took            -0.005707            -0.001311   \n",
       "172        broke            -0.072218            -0.161854   \n",
       "173        makes             0.047088             0.075098   \n",
       "174         stay            -0.030220            -0.071293   \n",
       "175      instead            -0.016242            -0.040411   \n",
       "176         idea            -0.067867            -0.152421   \n",
       "177         head            -0.034119            -0.070852   \n",
       "178         said            -0.034362            -0.058456   \n",
       "179         less            -0.002800             0.007464   \n",
       "180         went            -0.045452            -0.081201   \n",
       "181      working            -0.030264            -0.067136   \n",
       "182         high             0.015209             0.019207   \n",
       "183         unit            -0.055325            -0.107959   \n",
       "184        seems            -0.016585            -0.040065   \n",
       "185      picture            -0.031828            -0.064669   \n",
       "186   completely            -0.048952            -0.104243   \n",
       "187         wish             0.025947             0.045034   \n",
       "188       buying            -0.036287            -0.083473   \n",
       "189       babies             0.016587             0.023252   \n",
       "190          won            -0.000433            -0.000864   \n",
       "191          tub            -0.084962            -0.144248   \n",
       "192       almost             0.020599             0.040985   \n",
       "193       either            -0.033165            -0.069721   \n",
       "\n",
       "     coefficients [L2=10]  coefficients [L2=1e2]  coefficients [L2=1e3]  \\\n",
       "0                0.856938               0.880735               0.852262   \n",
       "1                0.059369               0.054209               0.037056   \n",
       "2                0.049318               0.042300               0.022413   \n",
       "3                0.445919               0.377037               0.154786   \n",
       "4                0.723518               0.603417               0.219053   \n",
       "5                0.014346               0.013918               0.019754   \n",
       "6               -0.240310              -0.218540              -0.118559   \n",
       "7               -0.041458              -0.037099              -0.009205   \n",
       "8                0.641557               0.540604               0.210677   \n",
       "9                0.312677               0.267211               0.112351   \n",
       "10              -0.108863              -0.088434              -0.020803   \n",
       "11               0.114545               0.099660               0.055971   \n",
       "12               0.179607               0.147550               0.050551   \n",
       "13              -0.139075              -0.125660              -0.063849   \n",
       "14               0.107847               0.093707               0.043484   \n",
       "15               0.003524               0.003692               0.007567   \n",
       "16               0.077395               0.068282               0.041329   \n",
       "17              -0.122271              -0.105208              -0.039179   \n",
       "18              -0.062840              -0.055636              -0.009315   \n",
       "19              -0.236441              -0.205863              -0.071484   \n",
       "20              -0.020200              -0.020724              -0.003879   \n",
       "21               0.137185               0.117036               0.056511   \n",
       "22              -0.026315              -0.024957              -0.009324   \n",
       "23               0.584335               0.482765               0.163122   \n",
       "24              -0.058204              -0.046538              -0.011110   \n",
       "25               0.009166               0.007928               0.008975   \n",
       "26               0.030806               0.028454               0.021173   \n",
       "27               0.079354               0.064317               0.020977   \n",
       "28               0.123584               0.103907               0.038186   \n",
       "29              -0.158816              -0.136305              -0.054362   \n",
       "..                    ...                    ...                    ...   \n",
       "164             -0.029225              -0.024301              -0.004732   \n",
       "165             -0.040408              -0.033992              -0.009972   \n",
       "166             -0.045936              -0.038571              -0.010726   \n",
       "167             -0.119920              -0.099658              -0.028113   \n",
       "168             -0.013268              -0.012215              -0.004294   \n",
       "169             -0.251925              -0.207194              -0.052394   \n",
       "170             -0.129368              -0.106139              -0.028238   \n",
       "171             -0.001401              -0.002572              -0.003503   \n",
       "172             -0.159637              -0.131044              -0.032660   \n",
       "173              0.074052               0.060706               0.020992   \n",
       "174             -0.070374              -0.058498              -0.014542   \n",
       "175             -0.039845              -0.032551              -0.007271   \n",
       "176             -0.150294              -0.122905              -0.030359   \n",
       "177             -0.069943              -0.058206              -0.015705   \n",
       "178             -0.057763              -0.048845              -0.016391   \n",
       "179              0.007238               0.004289              -0.002665   \n",
       "180             -0.080204              -0.067389              -0.021469   \n",
       "181             -0.066210              -0.054320              -0.013878   \n",
       "182              0.019015               0.016560               0.008683   \n",
       "183             -0.106555              -0.088466              -0.025636   \n",
       "184             -0.039560              -0.033053              -0.007993   \n",
       "185             -0.063897              -0.053901              -0.015688   \n",
       "186             -0.102837              -0.084717              -0.022232   \n",
       "187              0.044290               0.034790               0.009898   \n",
       "188             -0.082351              -0.067897              -0.016750   \n",
       "189              0.022949               0.019076               0.007687   \n",
       "190             -0.000851              -0.000685              -0.000182   \n",
       "191             -0.142546              -0.120599              -0.038997   \n",
       "192              0.040409               0.032966               0.009358   \n",
       "193             -0.068757              -0.056373              -0.014782   \n",
       "\n",
       "     coefficients [L2=1e5]  \n",
       "0                 0.998794  \n",
       "1                 0.000470  \n",
       "2                 0.000083  \n",
       "3                 0.002129  \n",
       "4                 0.003136  \n",
       "5                 0.000082  \n",
       "6                -0.002730  \n",
       "7                -0.000432  \n",
       "8                 0.003162  \n",
       "9                 0.001601  \n",
       "10               -0.000168  \n",
       "11                0.000793  \n",
       "12                0.000533  \n",
       "13               -0.001466  \n",
       "14                0.000634  \n",
       "15               -0.000060  \n",
       "16                0.000518  \n",
       "17               -0.000768  \n",
       "18               -0.000441  \n",
       "19               -0.001369  \n",
       "20               -0.000308  \n",
       "21                0.000740  \n",
       "22               -0.000384  \n",
       "23                0.002210  \n",
       "24               -0.000090  \n",
       "25                0.000002  \n",
       "26                0.000262  \n",
       "27                0.000272  \n",
       "28                0.000428  \n",
       "29               -0.000987  \n",
       "..                     ...  \n",
       "164              -0.000121  \n",
       "165              -0.000178  \n",
       "166              -0.000203  \n",
       "167              -0.000404  \n",
       "168              -0.000139  \n",
       "169              -0.000695  \n",
       "170              -0.000382  \n",
       "171              -0.000124  \n",
       "172              -0.000436  \n",
       "173               0.000228  \n",
       "174              -0.000240  \n",
       "175              -0.000122  \n",
       "176              -0.000406  \n",
       "177              -0.000257  \n",
       "178              -0.000269  \n",
       "179              -0.000128  \n",
       "180              -0.000361  \n",
       "181              -0.000204  \n",
       "182               0.000148  \n",
       "183              -0.000372  \n",
       "184              -0.000170  \n",
       "185              -0.000250  \n",
       "186              -0.000313  \n",
       "187               0.000038  \n",
       "188              -0.000262  \n",
       "189               0.000073  \n",
       "190              -0.000003  \n",
       "191              -0.000609  \n",
       "192               0.000072  \n",
       "193              -0.000207  \n",
       "\n",
       "[194 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_coefficients_to_table(coefficients_0_penalty, 'coefficients [L2=0]')\n",
    "add_coefficients_to_table(coefficients_4_penalty, 'coefficients [L2=4]')\n",
    "add_coefficients_to_table(coefficients_10_penalty, 'coefficients [L2=10]')\n",
    "add_coefficients_to_table(coefficients_1e2_penalty, 'coefficients [L2=1e2]')\n",
    "add_coefficients_to_table(coefficients_1e3_penalty, 'coefficients [L2=1e3]')\n",
    "add_coefficients_to_table(coefficients_1e5_penalty, 'coefficients [L2=1e5]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **the coefficients trained with L2 penalty 0**, find the 5 most positive words (with largest positive coefficients). Save them to **positive_words**. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to **negative_words**.\n",
    "\n",
    "**Quiz Question**. Which of the following is **not** listed in either **positive_words** or **negative_words**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'easy', 'loves', 'great', 'little']\n",
      "['money', 'thought', 'monitor', 'waste', 'would']\n"
     ]
    }
   ],
   "source": [
    "coefficients_0_temp = list(coefficients_0_penalty[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients_0_temp)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)\n",
    "positive_words = [word for word, coefficient in word_coefficient_tuples[0:5]]\n",
    "negative_words = [word for word, coefficient in word_coefficient_tuples[len(word_coefficient_tuples) - 5:len(word_coefficient_tuples)]]\n",
    "print( positive_words )\n",
    "print( negative_words )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us observe the effect of increasing L2 penalty on the 10 words just selected. We provide you with a utility function to  plot the coefficient path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = table.filter_by(column_name='word', values=positive_words)\n",
    "    table_negative_words = table.filter_by(column_name='word', values=negative_words)\n",
    "    del table_positive_words['word']\n",
    "    del table_negative_words['word']\n",
    "    \n",
    "    for i in range(len(positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_positive_words[i:i+1].to_numpy().flatten(),\n",
    "                 '-', label=positive_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    for i in range(len(negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_negative_words[i:i+1].to_numpy().flatten(),\n",
    "                 '-', label=negative_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate the plot. Use the plot to answer the following quiz question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'filter_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c52a559619f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmake_coefficient_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_penalty_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-7faa9f030469>\u001b[0m in \u001b[0;36mmake_coefficient_plot\u001b[1;34m(table, positive_words, negative_words, l2_penalty_list)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtable_positive_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpositive_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtable_negative_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnegative_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mtable_positive_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\SRI-ENVS\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'filter_by'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: (True/False) All coefficients consistently get smaller in size as the L2 penalty is increased.\n",
    "\n",
    "**Quiz Question**: (True/False) The relative order of coefficients is preserved as the L2 penalty is increased. (For example, if the coefficient for 'cat' was more positive than that for 'dog', this remains true as the L2 penalty increases.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy\n",
    "\n",
    "Now, let us compute the accuracy of the classifier model. Recall that the accuracy is given by\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "\n",
    "Recall from lecture that that the class prediction is calculated using\n",
    "$$\n",
    "\\hat{y}_i = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & h(\\mathbf{x}_i)^T\\mathbf{w} > 0 \\\\\n",
    "      -1 & h(\\mathbf{x}_i)^T\\mathbf{w} \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "**Note**: It is important to know that the model prediction code doesn't change even with the addition of an L2 penalty. The only thing that changes is the estimated coefficients used in this prediction.\n",
    "\n",
    "Based on the above, we will use the same code that was used in Module 3 assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.11319896 0.94731354 0.51620492 ... 1.60519964 0.86336172 1.53394106]\n",
      "[1.3500506  1.09607444 0.46707793 ... 2.11078401 1.12340797 1.87032574]\n"
     ]
    }
   ],
   "source": [
    "pred_0 = np.dot(feature_matrix_train, coefficients_0_penalty)\n",
    "print(pred_0)\n",
    "\n",
    "pred_4 = np.dot(feature_matrix_train, coefficients_4_penalty)\n",
    "print(pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here range is chaecked for predictions  i.e set range if x:1 x>1 else -1\n",
    "\n",
    "def get_classification_accuracy1(feature_matrix, sentiment, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    apply_threshold = np.vectorize(lambda x: 1. if x > 1  else -1.)\n",
    "    predictions = apply_threshold(scores)\n",
    "    \n",
    "    num_correct = (predictions == sentiment).sum()\n",
    "    accuracy = num_correct / len(feature_matrix)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compare the accuracy on the **training data** and **validation data** for all the models that were trained in this assignment.  We first calculate the accuracy values and then build a simple report summarizing the performance for the various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here with accuracy1 total acc is checked with       (x > 1)\n",
    "\n",
    "train_accuracy1 = {}\n",
    "train_accuracy1[0]   = get_classification_accuracy1(feature_matrix_train, sentiment_train, coefficients_0_penalty)\n",
    "train_accuracy1[4]   = get_classification_accuracy1(feature_matrix_train, sentiment_train, coefficients_4_penalty)\n",
    "train_accuracy1[10]  = get_classification_accuracy1(feature_matrix_train, sentiment_train, coefficients_10_penalty)\n",
    "train_accuracy1[1e2] = get_classification_accuracy1(feature_matrix_train, sentiment_train, coefficients_1e2_penalty)\n",
    "train_accuracy1[1e3] = get_classification_accuracy1(feature_matrix_train, sentiment_train, coefficients_1e3_penalty)\n",
    "train_accuracy1[1e5] = get_classification_accuracy1(feature_matrix_train, sentiment_train, coefficients_1e5_penalty)\n",
    "\n",
    "validation_accuracy1 = {}\n",
    "validation_accuracy1[0]   = get_classification_accuracy1(feature_matrix_valid, sentiment_valid, coefficients_0_penalty)\n",
    "validation_accuracy1[4]   = get_classification_accuracy1(feature_matrix_valid, sentiment_valid, coefficients_4_penalty)\n",
    "validation_accuracy1[10]  = get_classification_accuracy1(feature_matrix_valid, sentiment_valid, coefficients_10_penalty)\n",
    "validation_accuracy1[1e2] = get_classification_accuracy1(feature_matrix_valid, sentiment_valid, coefficients_1e2_penalty)\n",
    "validation_accuracy1[1e3] = get_classification_accuracy1(feature_matrix_valid, sentiment_valid, coefficients_1e3_penalty)\n",
    "validation_accuracy1[1e5] = get_classification_accuracy1(feature_matrix_valid, sentiment_valid, coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 penalty = 0\n",
      "train accuracy1 = 0.64405, validation_accuracy1 = 0.6536\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 4\n",
      "train accuracy1 = 0.6932, validation_accuracy1 = 0.696\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 10\n",
      "train accuracy1 = 0.69295, validation_accuracy1 = 0.6958\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100\n",
      "train accuracy1 = 0.6879, validation_accuracy1 = 0.6914\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 1000\n",
      "train accuracy1 = 0.6004, validation_accuracy1 = 0.6146\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100000\n",
      "train accuracy1 = 0.563, validation_accuracy1 = 0.5676\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a simple report\n",
    "for key in sorted(validation_accuracy1.keys()):\n",
    "    print (\"L2 penalty = %g\" % key )\n",
    "    print (\"train accuracy1 = %s, validation_accuracy1 = %s\" % (train_accuracy1[key], validation_accuracy1[key]) )\n",
    "    print (\"--------------------------------------------------------------------------------\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_accuracy(feature_matrix, sentiment, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    apply_threshold = np.vectorize(lambda x: 1. if x > 0  else -1.)\n",
    "    predictions = apply_threshold(scores)\n",
    "    \n",
    "    num_correct = (predictions == sentiment).sum()\n",
    "    accuracy = num_correct / len(feature_matrix)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = {}\n",
    "train_accuracy[0]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_0_penalty)\n",
    "train_accuracy[4]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_4_penalty)\n",
    "train_accuracy[10]  = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_10_penalty)\n",
    "train_accuracy[1e2] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e2_penalty)\n",
    "train_accuracy[1e3] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e3_penalty)\n",
    "train_accuracy[1e5] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e5_penalty)\n",
    "\n",
    "validation_accuracy = {}\n",
    "validation_accuracy[0]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_0_penalty)\n",
    "validation_accuracy[4]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_4_penalty)\n",
    "validation_accuracy[10]  = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_10_penalty)\n",
    "validation_accuracy[1e2] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e2_penalty)\n",
    "validation_accuracy[1e3] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e3_penalty)\n",
    "validation_accuracy[1e5] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 penalty = 0\n",
      "train accuracy = 0.7492, validation_accuracy = 0.7424\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 4\n",
      "train accuracy = 0.76825, validation_accuracy = 0.7628\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 10\n",
      "train accuracy = 0.7675, validation_accuracy = 0.762\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100\n",
      "train accuracy = 0.7595, validation_accuracy = 0.7552\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 1000\n",
      "train accuracy = 0.73525, validation_accuracy = 0.727\n",
      "--------------------------------------------------------------------------------\n",
      "L2 penalty = 100000\n",
      "train accuracy = 0.73435, validation_accuracy = 0.7256\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a simple report\n",
    "for key in sorted(validation_accuracy.keys()):\n",
    "    print (\"L2 penalty = %g\" % key )\n",
    "    print (\"train accuracy = %s, validation_accuracy = %s\" % (train_accuracy[key], validation_accuracy[key]) )\n",
    "    print (\"--------------------------------------------------------------------------------\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.tight_layout(pad=1.08, h_pad=None, w_pad=None, rect=None)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional. Plot accuracy on training and validation sets over choice of L2 penalty.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "sorted_list = sorted(train_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], 'bo-', linewidth=4, label='Training accuracy')\n",
    "sorted_list = sorted(validation_accuracy.items(), key=lambda x:x[0])\n",
    "plt.plot([p[0] for p in sorted_list], [p[1] for p in sorted_list], 'ro-', linewidth=4, label='Validation accuracy')\n",
    "plt.xscale('symlog')\n",
    "plt.axis([0, 1e3, 0.72, 0.77])\n",
    "plt.legend(loc='lower left')\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.tight_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Quiz Question**: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the **highest** accuracy on the **training** data?\n",
    "* **Quiz Question**: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the **highest** accuracy on the **validation** data?\n",
    "* **Quiz Question**: Does the **highest** accuracy on the **training** data imply that the model is the best one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
