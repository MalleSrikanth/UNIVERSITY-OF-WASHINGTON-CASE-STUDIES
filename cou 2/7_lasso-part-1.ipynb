{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using sklearn , though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6561</td>\n",
       "      <td>-122.005</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008000270</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2414600126</td>\n",
       "      <td>20150415T000000</td>\n",
       "      <td>229500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>7470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>730</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5123</td>\n",
       "      <td>-122.337</td>\n",
       "      <td>1780</td>\n",
       "      <td>8113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3793500160</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>323000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1890</td>\n",
       "      <td>6560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.3684</td>\n",
       "      <td>-122.031</td>\n",
       "      <td>2390</td>\n",
       "      <td>7570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1736800520</td>\n",
       "      <td>20150403T000000</td>\n",
       "      <td>662500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3560</td>\n",
       "      <td>9796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1860</td>\n",
       "      <td>1700</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98007</td>\n",
       "      <td>47.6007</td>\n",
       "      <td>-122.145</td>\n",
       "      <td>2210</td>\n",
       "      <td>8925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9212900260</td>\n",
       "      <td>20140527T000000</td>\n",
       "      <td>468000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1160</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>860</td>\n",
       "      <td>300</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6900</td>\n",
       "      <td>-122.292</td>\n",
       "      <td>1330</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>114101516</td>\n",
       "      <td>20140528T000000</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1430</td>\n",
       "      <td>19901</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1430</td>\n",
       "      <td>0</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7558</td>\n",
       "      <td>-122.229</td>\n",
       "      <td>1780</td>\n",
       "      <td>12697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6054650070</td>\n",
       "      <td>20141007T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1370</td>\n",
       "      <td>9680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1370</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6127</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1370</td>\n",
       "      <td>10208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1175000570</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>530000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1810</td>\n",
       "      <td>4850</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1810</td>\n",
       "      <td>0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6700</td>\n",
       "      <td>-122.394</td>\n",
       "      <td>1360</td>\n",
       "      <td>4850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9297300055</td>\n",
       "      <td>20150124T000000</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2950</td>\n",
       "      <td>5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1980</td>\n",
       "      <td>970</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5714</td>\n",
       "      <td>-122.375</td>\n",
       "      <td>2140</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1875500060</td>\n",
       "      <td>20140731T000000</td>\n",
       "      <td>395000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1890</td>\n",
       "      <td>14040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>98019</td>\n",
       "      <td>47.7277</td>\n",
       "      <td>-121.962</td>\n",
       "      <td>1890</td>\n",
       "      <td>14018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6865200140</td>\n",
       "      <td>20140529T000000</td>\n",
       "      <td>485000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1600</td>\n",
       "      <td>4300</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>1916</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6648</td>\n",
       "      <td>-122.343</td>\n",
       "      <td>1610</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16000397</td>\n",
       "      <td>20141205T000000</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1200</td>\n",
       "      <td>9850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>98002</td>\n",
       "      <td>47.3089</td>\n",
       "      <td>-122.210</td>\n",
       "      <td>1060</td>\n",
       "      <td>5095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7983200060</td>\n",
       "      <td>20150424T000000</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1250</td>\n",
       "      <td>9774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1250</td>\n",
       "      <td>0</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3343</td>\n",
       "      <td>-122.306</td>\n",
       "      <td>1280</td>\n",
       "      <td>8850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6300500875</td>\n",
       "      <td>20140514T000000</td>\n",
       "      <td>385000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1620</td>\n",
       "      <td>4980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>860</td>\n",
       "      <td>760</td>\n",
       "      <td>1947</td>\n",
       "      <td>0</td>\n",
       "      <td>98133</td>\n",
       "      <td>47.7025</td>\n",
       "      <td>-122.341</td>\n",
       "      <td>1400</td>\n",
       "      <td>4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2524049179</td>\n",
       "      <td>20140826T000000</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3050</td>\n",
       "      <td>44867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2330</td>\n",
       "      <td>720</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5316</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>4110</td>\n",
       "      <td>20336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7137970340</td>\n",
       "      <td>20140703T000000</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2270</td>\n",
       "      <td>6300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2270</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98092</td>\n",
       "      <td>47.3266</td>\n",
       "      <td>-122.169</td>\n",
       "      <td>2240</td>\n",
       "      <td>7005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8091400200</td>\n",
       "      <td>20140516T000000</td>\n",
       "      <td>252700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1070</td>\n",
       "      <td>9643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>98030</td>\n",
       "      <td>47.3533</td>\n",
       "      <td>-122.166</td>\n",
       "      <td>1220</td>\n",
       "      <td>8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3814700200</td>\n",
       "      <td>20141120T000000</td>\n",
       "      <td>329000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2450</td>\n",
       "      <td>6500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2450</td>\n",
       "      <td>0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>98030</td>\n",
       "      <td>47.3739</td>\n",
       "      <td>-122.172</td>\n",
       "      <td>2200</td>\n",
       "      <td>6865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1202000200</td>\n",
       "      <td>20141103T000000</td>\n",
       "      <td>233000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1710</td>\n",
       "      <td>4697</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>1941</td>\n",
       "      <td>0</td>\n",
       "      <td>98002</td>\n",
       "      <td>47.3048</td>\n",
       "      <td>-122.218</td>\n",
       "      <td>1030</td>\n",
       "      <td>4705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1794500383</td>\n",
       "      <td>20140626T000000</td>\n",
       "      <td>937000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2450</td>\n",
       "      <td>2691</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1750</td>\n",
       "      <td>700</td>\n",
       "      <td>1915</td>\n",
       "      <td>0</td>\n",
       "      <td>98119</td>\n",
       "      <td>47.6386</td>\n",
       "      <td>-122.360</td>\n",
       "      <td>1760</td>\n",
       "      <td>3573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3303700376</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>667000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1400</td>\n",
       "      <td>1581</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1909</td>\n",
       "      <td>0</td>\n",
       "      <td>98112</td>\n",
       "      <td>47.6221</td>\n",
       "      <td>-122.314</td>\n",
       "      <td>1860</td>\n",
       "      <td>3861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5101402488</td>\n",
       "      <td>20140624T000000</td>\n",
       "      <td>438000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1520</td>\n",
       "      <td>6380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>790</td>\n",
       "      <td>730</td>\n",
       "      <td>1948</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6950</td>\n",
       "      <td>-122.304</td>\n",
       "      <td>1520</td>\n",
       "      <td>6235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1873100390</td>\n",
       "      <td>20150302T000000</td>\n",
       "      <td>719000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2570</td>\n",
       "      <td>7173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2570</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.7073</td>\n",
       "      <td>-122.110</td>\n",
       "      <td>2630</td>\n",
       "      <td>6026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21583</th>\n",
       "      <td>2025049203</td>\n",
       "      <td>20140610T000000</td>\n",
       "      <td>399950.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>710</td>\n",
       "      <td>1157</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>1943</td>\n",
       "      <td>0</td>\n",
       "      <td>98102</td>\n",
       "      <td>47.6413</td>\n",
       "      <td>-122.329</td>\n",
       "      <td>1370</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21584</th>\n",
       "      <td>952006823</td>\n",
       "      <td>20141202T000000</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1260</td>\n",
       "      <td>900</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>940</td>\n",
       "      <td>320</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>47.5621</td>\n",
       "      <td>-122.384</td>\n",
       "      <td>1310</td>\n",
       "      <td>1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21585</th>\n",
       "      <td>3832050760</td>\n",
       "      <td>20140828T000000</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1870</td>\n",
       "      <td>5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1870</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3339</td>\n",
       "      <td>-122.055</td>\n",
       "      <td>2170</td>\n",
       "      <td>5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21586</th>\n",
       "      <td>2767604724</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>505000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1430</td>\n",
       "      <td>1201</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1430</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6707</td>\n",
       "      <td>-122.381</td>\n",
       "      <td>1430</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21587</th>\n",
       "      <td>6632300207</td>\n",
       "      <td>20150305T000000</td>\n",
       "      <td>385000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1520</td>\n",
       "      <td>1488</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1520</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7337</td>\n",
       "      <td>-122.309</td>\n",
       "      <td>1520</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21588</th>\n",
       "      <td>2767600688</td>\n",
       "      <td>20141113T000000</td>\n",
       "      <td>414500.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1210</td>\n",
       "      <td>1278</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1020</td>\n",
       "      <td>190</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6756</td>\n",
       "      <td>-122.375</td>\n",
       "      <td>1210</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21589</th>\n",
       "      <td>7570050450</td>\n",
       "      <td>20140910T000000</td>\n",
       "      <td>347500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2540</td>\n",
       "      <td>4760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2540</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.3452</td>\n",
       "      <td>-122.022</td>\n",
       "      <td>2540</td>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21590</th>\n",
       "      <td>7430200100</td>\n",
       "      <td>20140514T000000</td>\n",
       "      <td>1222500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4910</td>\n",
       "      <td>9444</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3110</td>\n",
       "      <td>1800</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6502</td>\n",
       "      <td>-122.066</td>\n",
       "      <td>4560</td>\n",
       "      <td>11063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21591</th>\n",
       "      <td>4140940150</td>\n",
       "      <td>20141002T000000</td>\n",
       "      <td>572000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2770</td>\n",
       "      <td>3852</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2770</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5001</td>\n",
       "      <td>-122.232</td>\n",
       "      <td>1810</td>\n",
       "      <td>5641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>1931300412</td>\n",
       "      <td>20150416T000000</td>\n",
       "      <td>475000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1190</td>\n",
       "      <td>1200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1190</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6542</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1180</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>8672200110</td>\n",
       "      <td>20150317T000000</td>\n",
       "      <td>1088000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4170</td>\n",
       "      <td>8142</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4170</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98056</td>\n",
       "      <td>47.5354</td>\n",
       "      <td>-122.181</td>\n",
       "      <td>3030</td>\n",
       "      <td>7980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>5087900040</td>\n",
       "      <td>20141017T000000</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2500</td>\n",
       "      <td>5995</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3749</td>\n",
       "      <td>-122.107</td>\n",
       "      <td>2530</td>\n",
       "      <td>5988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>1972201967</td>\n",
       "      <td>20141031T000000</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1530</td>\n",
       "      <td>981</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1480</td>\n",
       "      <td>50</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6533</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>7502800100</td>\n",
       "      <td>20140813T000000</td>\n",
       "      <td>679950.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3600</td>\n",
       "      <td>9437</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3600</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98059</td>\n",
       "      <td>47.4822</td>\n",
       "      <td>-122.131</td>\n",
       "      <td>3550</td>\n",
       "      <td>9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>191100405</td>\n",
       "      <td>20150421T000000</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3410</td>\n",
       "      <td>10125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3410</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5653</td>\n",
       "      <td>-122.223</td>\n",
       "      <td>2290</td>\n",
       "      <td>10125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>8956200760</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>541800.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3118</td>\n",
       "      <td>7866</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3118</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98001</td>\n",
       "      <td>47.2931</td>\n",
       "      <td>-122.264</td>\n",
       "      <td>2673</td>\n",
       "      <td>6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>7202300110</td>\n",
       "      <td>20140915T000000</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3990</td>\n",
       "      <td>7838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3990</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6857</td>\n",
       "      <td>-122.046</td>\n",
       "      <td>3370</td>\n",
       "      <td>6814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21600</th>\n",
       "      <td>249000205</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>1537000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4470</td>\n",
       "      <td>8088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>4470</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.6321</td>\n",
       "      <td>-122.200</td>\n",
       "      <td>2780</td>\n",
       "      <td>8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21601</th>\n",
       "      <td>5100403806</td>\n",
       "      <td>20150407T000000</td>\n",
       "      <td>467000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1425</td>\n",
       "      <td>1179</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1425</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.6963</td>\n",
       "      <td>-122.318</td>\n",
       "      <td>1285</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21602</th>\n",
       "      <td>844000965</td>\n",
       "      <td>20140626T000000</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1500</td>\n",
       "      <td>11968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98010</td>\n",
       "      <td>47.3095</td>\n",
       "      <td>-122.002</td>\n",
       "      <td>1320</td>\n",
       "      <td>11303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21603</th>\n",
       "      <td>7852140040</td>\n",
       "      <td>20140825T000000</td>\n",
       "      <td>507250.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2270</td>\n",
       "      <td>5536</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2270</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98065</td>\n",
       "      <td>47.5389</td>\n",
       "      <td>-121.881</td>\n",
       "      <td>2270</td>\n",
       "      <td>5731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21604</th>\n",
       "      <td>9834201367</td>\n",
       "      <td>20150126T000000</td>\n",
       "      <td>429000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1490</td>\n",
       "      <td>1126</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1490</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5699</td>\n",
       "      <td>-122.288</td>\n",
       "      <td>1400</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21605</th>\n",
       "      <td>3448900210</td>\n",
       "      <td>20141014T000000</td>\n",
       "      <td>610685.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2520</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98056</td>\n",
       "      <td>47.5137</td>\n",
       "      <td>-122.167</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21606</th>\n",
       "      <td>7936000429</td>\n",
       "      <td>20150326T000000</td>\n",
       "      <td>1007500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3510</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2600</td>\n",
       "      <td>910</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5537</td>\n",
       "      <td>-122.398</td>\n",
       "      <td>2050</td>\n",
       "      <td>6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21607</th>\n",
       "      <td>2997800021</td>\n",
       "      <td>20150219T000000</td>\n",
       "      <td>475000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1310</td>\n",
       "      <td>1294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1180</td>\n",
       "      <td>130</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>47.5773</td>\n",
       "      <td>-122.409</td>\n",
       "      <td>1330</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>263000018</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>20140623T000000</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>291310100</td>\n",
       "      <td>20150116T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             date      price  bedrooms  bathrooms  \\\n",
       "0      7129300520  20141013T000000   221900.0         3       1.00   \n",
       "1      6414100192  20141209T000000   538000.0         3       2.25   \n",
       "2      5631500400  20150225T000000   180000.0         2       1.00   \n",
       "3      2487200875  20141209T000000   604000.0         4       3.00   \n",
       "4      1954400510  20150218T000000   510000.0         3       2.00   \n",
       "5      7237550310  20140512T000000  1225000.0         4       4.50   \n",
       "6      1321400060  20140627T000000   257500.0         3       2.25   \n",
       "7      2008000270  20150115T000000   291850.0         3       1.50   \n",
       "8      2414600126  20150415T000000   229500.0         3       1.00   \n",
       "9      3793500160  20150312T000000   323000.0         3       2.50   \n",
       "10     1736800520  20150403T000000   662500.0         3       2.50   \n",
       "11     9212900260  20140527T000000   468000.0         2       1.00   \n",
       "12      114101516  20140528T000000   310000.0         3       1.00   \n",
       "13     6054650070  20141007T000000   400000.0         3       1.75   \n",
       "14     1175000570  20150312T000000   530000.0         5       2.00   \n",
       "15     9297300055  20150124T000000   650000.0         4       3.00   \n",
       "16     1875500060  20140731T000000   395000.0         3       2.00   \n",
       "17     6865200140  20140529T000000   485000.0         4       1.00   \n",
       "18       16000397  20141205T000000   189000.0         2       1.00   \n",
       "19     7983200060  20150424T000000   230000.0         3       1.00   \n",
       "20     6300500875  20140514T000000   385000.0         4       1.75   \n",
       "21     2524049179  20140826T000000  2000000.0         3       2.75   \n",
       "22     7137970340  20140703T000000   285000.0         5       2.50   \n",
       "23     8091400200  20140516T000000   252700.0         2       1.50   \n",
       "24     3814700200  20141120T000000   329000.0         3       2.25   \n",
       "25     1202000200  20141103T000000   233000.0         3       2.00   \n",
       "26     1794500383  20140626T000000   937000.0         3       1.75   \n",
       "27     3303700376  20141201T000000   667000.0         3       1.00   \n",
       "28     5101402488  20140624T000000   438000.0         3       1.75   \n",
       "29     1873100390  20150302T000000   719000.0         4       2.50   \n",
       "...           ...              ...        ...       ...        ...   \n",
       "21583  2025049203  20140610T000000   399950.0         2       1.00   \n",
       "21584   952006823  20141202T000000   380000.0         3       2.50   \n",
       "21585  3832050760  20140828T000000   270000.0         3       2.50   \n",
       "21586  2767604724  20141015T000000   505000.0         2       2.50   \n",
       "21587  6632300207  20150305T000000   385000.0         3       2.50   \n",
       "21588  2767600688  20141113T000000   414500.0         2       1.50   \n",
       "21589  7570050450  20140910T000000   347500.0         3       2.50   \n",
       "21590  7430200100  20140514T000000  1222500.0         4       3.50   \n",
       "21591  4140940150  20141002T000000   572000.0         4       2.75   \n",
       "21592  1931300412  20150416T000000   475000.0         3       2.25   \n",
       "21593  8672200110  20150317T000000  1088000.0         5       3.75   \n",
       "21594  5087900040  20141017T000000   350000.0         4       2.75   \n",
       "21595  1972201967  20141031T000000   520000.0         2       2.25   \n",
       "21596  7502800100  20140813T000000   679950.0         5       2.75   \n",
       "21597   191100405  20150421T000000  1575000.0         4       3.25   \n",
       "21598  8956200760  20141013T000000   541800.0         4       2.50   \n",
       "21599  7202300110  20140915T000000   810000.0         4       3.00   \n",
       "21600   249000205  20141015T000000  1537000.0         5       3.75   \n",
       "21601  5100403806  20150407T000000   467000.0         3       2.50   \n",
       "21602   844000965  20140626T000000   224000.0         3       1.75   \n",
       "21603  7852140040  20140825T000000   507250.0         3       2.50   \n",
       "21604  9834201367  20150126T000000   429000.0         3       2.00   \n",
       "21605  3448900210  20141014T000000   610685.0         4       2.50   \n",
       "21606  7936000429  20150326T000000  1007500.0         4       3.50   \n",
       "21607  2997800021  20150219T000000   475000.0         3       2.50   \n",
       "21608   263000018  20140521T000000   360000.0         3       2.50   \n",
       "21609  6600060120  20150223T000000   400000.0         4       2.50   \n",
       "21610  1523300141  20140623T000000   402101.0         2       0.75   \n",
       "21611   291310100  20150116T000000   400000.0         3       2.50   \n",
       "21612  1523300157  20141015T000000   325000.0         2       0.75   \n",
       "\n",
       "       sqft_living  sqft_lot  floors  waterfront  view     ...      grade  \\\n",
       "0             1180      5650     1.0           0     0     ...          7   \n",
       "1             2570      7242     2.0           0     0     ...          7   \n",
       "2              770     10000     1.0           0     0     ...          6   \n",
       "3             1960      5000     1.0           0     0     ...          7   \n",
       "4             1680      8080     1.0           0     0     ...          8   \n",
       "5             5420    101930     1.0           0     0     ...         11   \n",
       "6             1715      6819     2.0           0     0     ...          7   \n",
       "7             1060      9711     1.0           0     0     ...          7   \n",
       "8             1780      7470     1.0           0     0     ...          7   \n",
       "9             1890      6560     2.0           0     0     ...          7   \n",
       "10            3560      9796     1.0           0     0     ...          8   \n",
       "11            1160      6000     1.0           0     0     ...          7   \n",
       "12            1430     19901     1.5           0     0     ...          7   \n",
       "13            1370      9680     1.0           0     0     ...          7   \n",
       "14            1810      4850     1.5           0     0     ...          7   \n",
       "15            2950      5000     2.0           0     3     ...          9   \n",
       "16            1890     14040     2.0           0     0     ...          7   \n",
       "17            1600      4300     1.5           0     0     ...          7   \n",
       "18            1200      9850     1.0           0     0     ...          7   \n",
       "19            1250      9774     1.0           0     0     ...          7   \n",
       "20            1620      4980     1.0           0     0     ...          7   \n",
       "21            3050     44867     1.0           0     4     ...          9   \n",
       "22            2270      6300     2.0           0     0     ...          8   \n",
       "23            1070      9643     1.0           0     0     ...          7   \n",
       "24            2450      6500     2.0           0     0     ...          8   \n",
       "25            1710      4697     1.5           0     0     ...          6   \n",
       "26            2450      2691     2.0           0     0     ...          8   \n",
       "27            1400      1581     1.5           0     0     ...          8   \n",
       "28            1520      6380     1.0           0     0     ...          7   \n",
       "29            2570      7173     2.0           0     0     ...          8   \n",
       "...            ...       ...     ...         ...   ...     ...        ...   \n",
       "21583          710      1157     2.0           0     0     ...          7   \n",
       "21584         1260       900     2.0           0     0     ...          7   \n",
       "21585         1870      5000     2.0           0     0     ...          7   \n",
       "21586         1430      1201     3.0           0     0     ...          8   \n",
       "21587         1520      1488     3.0           0     0     ...          8   \n",
       "21588         1210      1278     2.0           0     0     ...          8   \n",
       "21589         2540      4760     2.0           0     0     ...          8   \n",
       "21590         4910      9444     1.5           0     0     ...         11   \n",
       "21591         2770      3852     2.0           0     0     ...          8   \n",
       "21592         1190      1200     3.0           0     0     ...          8   \n",
       "21593         4170      8142     2.0           0     2     ...         10   \n",
       "21594         2500      5995     2.0           0     0     ...          8   \n",
       "21595         1530       981     3.0           0     0     ...          8   \n",
       "21596         3600      9437     2.0           0     0     ...          9   \n",
       "21597         3410     10125     2.0           0     0     ...         10   \n",
       "21598         3118      7866     2.0           0     2     ...          9   \n",
       "21599         3990      7838     2.0           0     0     ...          9   \n",
       "21600         4470      8088     2.0           0     0     ...         11   \n",
       "21601         1425      1179     3.0           0     0     ...          8   \n",
       "21602         1500     11968     1.0           0     0     ...          6   \n",
       "21603         2270      5536     2.0           0     0     ...          8   \n",
       "21604         1490      1126     3.0           0     0     ...          8   \n",
       "21605         2520      6023     2.0           0     0     ...          9   \n",
       "21606         3510      7200     2.0           0     0     ...          9   \n",
       "21607         1310      1294     2.0           0     0     ...          8   \n",
       "21608         1530      1131     3.0           0     0     ...          8   \n",
       "21609         2310      5813     2.0           0     0     ...          8   \n",
       "21610         1020      1350     2.0           0     0     ...          7   \n",
       "21611         1600      2388     2.0           0     0     ...          8   \n",
       "21612         1020      1076     2.0           0     0     ...          7   \n",
       "\n",
       "       sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0            1180              0      1955             0    98178  47.5112   \n",
       "1            2170            400      1951          1991    98125  47.7210   \n",
       "2             770              0      1933             0    98028  47.7379   \n",
       "3            1050            910      1965             0    98136  47.5208   \n",
       "4            1680              0      1987             0    98074  47.6168   \n",
       "5            3890           1530      2001             0    98053  47.6561   \n",
       "6            1715              0      1995             0    98003  47.3097   \n",
       "7            1060              0      1963             0    98198  47.4095   \n",
       "8            1050            730      1960             0    98146  47.5123   \n",
       "9            1890              0      2003             0    98038  47.3684   \n",
       "10           1860           1700      1965             0    98007  47.6007   \n",
       "11            860            300      1942             0    98115  47.6900   \n",
       "12           1430              0      1927             0    98028  47.7558   \n",
       "13           1370              0      1977             0    98074  47.6127   \n",
       "14           1810              0      1900             0    98107  47.6700   \n",
       "15           1980            970      1979             0    98126  47.5714   \n",
       "16           1890              0      1994             0    98019  47.7277   \n",
       "17           1600              0      1916             0    98103  47.6648   \n",
       "18           1200              0      1921             0    98002  47.3089   \n",
       "19           1250              0      1969             0    98003  47.3343   \n",
       "20            860            760      1947             0    98133  47.7025   \n",
       "21           2330            720      1968             0    98040  47.5316   \n",
       "22           2270              0      1995             0    98092  47.3266   \n",
       "23           1070              0      1985             0    98030  47.3533   \n",
       "24           2450              0      1985             0    98030  47.3739   \n",
       "25           1710              0      1941             0    98002  47.3048   \n",
       "26           1750            700      1915             0    98119  47.6386   \n",
       "27           1400              0      1909             0    98112  47.6221   \n",
       "28            790            730      1948             0    98115  47.6950   \n",
       "29           2570              0      2005             0    98052  47.7073   \n",
       "...           ...            ...       ...           ...      ...      ...   \n",
       "21583         710              0      1943             0    98102  47.6413   \n",
       "21584         940            320      2007             0    98116  47.5621   \n",
       "21585        1870              0      2009             0    98042  47.3339   \n",
       "21586        1430              0      2009             0    98107  47.6707   \n",
       "21587        1520              0      2006             0    98125  47.7337   \n",
       "21588        1020            190      2007             0    98117  47.6756   \n",
       "21589        2540              0      2010             0    98038  47.3452   \n",
       "21590        3110           1800      2007             0    98074  47.6502   \n",
       "21591        2770              0      2014             0    98178  47.5001   \n",
       "21592        1190              0      2008             0    98103  47.6542   \n",
       "21593        4170              0      2006             0    98056  47.5354   \n",
       "21594        2500              0      2008             0    98042  47.3749   \n",
       "21595        1480             50      2006             0    98103  47.6533   \n",
       "21596        3600              0      2014             0    98059  47.4822   \n",
       "21597        3410              0      2007             0    98040  47.5653   \n",
       "21598        3118              0      2014             0    98001  47.2931   \n",
       "21599        3990              0      2003             0    98053  47.6857   \n",
       "21600        4470              0      2008             0    98004  47.6321   \n",
       "21601        1425              0      2008             0    98125  47.6963   \n",
       "21602        1500              0      2014             0    98010  47.3095   \n",
       "21603        2270              0      2003             0    98065  47.5389   \n",
       "21604        1490              0      2014             0    98144  47.5699   \n",
       "21605        2520              0      2014             0    98056  47.5137   \n",
       "21606        2600            910      2009             0    98136  47.5537   \n",
       "21607        1180            130      2008             0    98116  47.5773   \n",
       "21608        1530              0      2009             0    98103  47.6993   \n",
       "21609        2310              0      2014             0    98146  47.5107   \n",
       "21610        1020              0      2009             0    98144  47.5944   \n",
       "21611        1600              0      2004             0    98027  47.5345   \n",
       "21612        1020              0      2008             0    98144  47.5941   \n",
       "\n",
       "          long  sqft_living15  sqft_lot15  \n",
       "0     -122.257           1340        5650  \n",
       "1     -122.319           1690        7639  \n",
       "2     -122.233           2720        8062  \n",
       "3     -122.393           1360        5000  \n",
       "4     -122.045           1800        7503  \n",
       "5     -122.005           4760      101930  \n",
       "6     -122.327           2238        6819  \n",
       "7     -122.315           1650        9711  \n",
       "8     -122.337           1780        8113  \n",
       "9     -122.031           2390        7570  \n",
       "10    -122.145           2210        8925  \n",
       "11    -122.292           1330        6000  \n",
       "12    -122.229           1780       12697  \n",
       "13    -122.045           1370       10208  \n",
       "14    -122.394           1360        4850  \n",
       "15    -122.375           2140        4000  \n",
       "16    -121.962           1890       14018  \n",
       "17    -122.343           1610        4300  \n",
       "18    -122.210           1060        5095  \n",
       "19    -122.306           1280        8850  \n",
       "20    -122.341           1400        4980  \n",
       "21    -122.233           4110       20336  \n",
       "22    -122.169           2240        7005  \n",
       "23    -122.166           1220        8386  \n",
       "24    -122.172           2200        6865  \n",
       "25    -122.218           1030        4705  \n",
       "26    -122.360           1760        3573  \n",
       "27    -122.314           1860        3861  \n",
       "28    -122.304           1520        6235  \n",
       "29    -122.110           2630        6026  \n",
       "...        ...            ...         ...  \n",
       "21583 -122.329           1370        1173  \n",
       "21584 -122.384           1310        1415  \n",
       "21585 -122.055           2170        5399  \n",
       "21586 -122.381           1430        1249  \n",
       "21587 -122.309           1520        1497  \n",
       "21588 -122.375           1210        1118  \n",
       "21589 -122.022           2540        4571  \n",
       "21590 -122.066           4560       11063  \n",
       "21591 -122.232           1810        5641  \n",
       "21592 -122.346           1180        1224  \n",
       "21593 -122.181           3030        7980  \n",
       "21594 -122.107           2530        5988  \n",
       "21595 -122.346           1530        1282  \n",
       "21596 -122.131           3550        9421  \n",
       "21597 -122.223           2290       10125  \n",
       "21598 -122.264           2673        6500  \n",
       "21599 -122.046           3370        6814  \n",
       "21600 -122.200           2780        8964  \n",
       "21601 -122.318           1285        1253  \n",
       "21602 -122.002           1320       11303  \n",
       "21603 -121.881           2270        5731  \n",
       "21604 -122.288           1400        1230  \n",
       "21605 -122.167           2520        6023  \n",
       "21606 -122.398           2050        6200  \n",
       "21607 -122.409           1330        1265  \n",
       "21608 -122.346           1530        1509  \n",
       "21609 -122.362           1830        7200  \n",
       "21610 -122.299           1020        2007  \n",
       "21611 -122.069           1410        1287  \n",
       "21612 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('kc_house_data.csv')\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in sklearn . (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 22) (21613,)\n"
     ]
    }
   ],
   "source": [
    "x = sales.drop(['id','date','price'] ,axis =1)\n",
    "y = sales['price']\n",
    "print(x.shape ,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10806, 22) (10806,)\n",
      "(10807, 22) (10807,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train ,x_test ,y_train ,y_test = train_test_split(x , y, test_size = 0.5 ,random_state = 40)\n",
    "print(x_train.shape ,y_train.shape )\n",
    "print(x_test.shape ,y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_all = Lasso(alpha = 0.1)\n",
    "model_all.fit(x ,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.25254391e+04,  4.90898185e+04,  7.19334369e+02,  6.91648064e-01,\n",
       "       -2.15267326e+04,  5.73929920e+05,  4.71910222e+04,  3.42111148e+04,\n",
       "        1.01312124e+05, -1.09623994e+02, -1.22986506e+02, -2.41615194e+03,\n",
       "        2.84596900e+01, -6.08222473e+02,  5.85114688e+05, -1.64071862e+05,\n",
       "        4.23679393e+01, -1.27407005e-01, -4.54271766e+04, -5.09720008e+02,\n",
       "        1.63680743e+02,  9.55826416e+03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16830195.65056218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `LinearRegression()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `LinearRegression()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+01 3.16227766e+01 1.00000000e+02 3.16227766e+02\n",
      " 1.00000000e+03 3.16227766e+03 1.00000000e+04 3.16227766e+04\n",
      " 1.00000000e+05 3.16227766e+05 1.00000000e+06 3.16227766e+06\n",
      " 1.00000000e+07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [219362.60102225 334550.22355762 238386.13909558 ...  49349.93508861\n",
      " 624365.70967354 227031.31836483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [219502.68518653 334629.26888252 239330.92532446 ...  49804.79112229\n",
      " 624269.50046523 227571.8057647 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [219945.67020596 334879.23215432 242318.60170541 ...  51243.17218096\n",
      " 623965.2602434  229280.97700429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221465.15445703 335706.43223233 251397.77659262 ...  55049.38710636\n",
      " 623192.95624665 235211.65154663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [230840.83345628 334637.85727802 275533.68232121 ...  57619.38253156\n",
      " 623682.10810954 264344.35967581]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [254720.37949868 323820.3866461  336516.39157757 ...  79944.94155418\n",
      " 625250.57155184 306417.01831191]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [308156.81539245 290950.24302742 411455.668628   ... 169937.40135995\n",
      " 636629.81159108 319649.43289704]\n",
      "predictions [286775.69059776 319575.69054909 354705.11715466 ... 207125.43379532\n",
      " 691990.58423911 332956.97679978]\n",
      "predictions [226364.27093595 347293.49406047 394227.79510041 ... 254312.94007418\n",
      " 755360.5822794  344469.5248796 ]\n",
      "predictions [237488.07241961 313589.44870142 424217.10042297 ... 247637.8204939\n",
      " 705184.4006325  332570.21533558]\n",
      "predictions [240130.61859708 307879.83568847 451573.89179166 ... 240021.0046809\n",
      " 656819.70002684 307137.36372482]\n",
      "predictions [225646.20169038 295334.52515208 485075.86189575 ... 247249.86570308\n",
      " 614530.91442754 284578.39487094]\n",
      "predictions [242241.98683671 313184.79154691 492368.73215463 ... 264488.79478936\n",
      " 619347.74115762 298764.88034169]\n",
      "min_error 412692754837330.5 best_penalty 10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l1_penalty_values=np.logspace(1,7, num=13)\n",
    "#l1_penalty_values = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "print(l1_penalty_values)\n",
    "\n",
    "min_error=0\n",
    "best_penalty=None\n",
    "test_errors=[]\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model = Lasso(alpha = l1_penalty)\n",
    "    model.fit(x_train ,y_train)\n",
    "    predictions=model.predict(x_train)\n",
    "    print('predictions', predictions)\n",
    "    rss=((predictions-y_train)**2).sum()\n",
    "    test_errors.append(rss)\n",
    "    if min_error is 0 or rss<min_error:\n",
    "        min_error=rss\n",
    "        best_penalty=l1_penalty\n",
    "print('min_error', min_error ,'best_penalty', best_penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412692754837330.5 10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[412692754837330.5,\n",
       " 412698208711983.75,\n",
       " 412752747618398.1,\n",
       " 413251595488445.25,\n",
       " 416387097180440.4,\n",
       " 440107422681282.8,\n",
       " 519288535165147.9,\n",
       " 565323845085829.0,\n",
       " 672246229893330.8,\n",
       " 693153694786674.0,\n",
       " 719403041587332.5,\n",
       " 753865363284896.8,\n",
       " 762209036101027.9]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (min_error,best_penalty)\n",
    "test_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *** What was the best value for the `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_predicted [1057109.2527447   692897.28310538  282588.24063628 ...  862125.93988311\n",
      "  353162.27211694  286040.33019827]\n",
      "RSS 397448272456179.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "best_penalty\n",
    "#using test data best rss (with using best_penalty)\n",
    "model = Lasso(alpha= best_penalty)\n",
    "model.fit(x_train ,y_train)\n",
    "price_predicted = model.predict(x_test)\n",
    "print('price_predicted', price_predicted)\n",
    "RSS = ((price_predicted-y_test)**2).sum()\n",
    "print ('RSS', RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01037396e+04,  5.24430540e+04,  7.23308357e+02,  5.90388750e-01,\n",
       "       -4.74285891e+04,  6.50648323e+05,  4.45505689e+04,  3.36137824e+04,\n",
       "        9.99760117e+04, -1.00310387e+02, -1.26723518e+02, -2.49570007e+03,\n",
       "        3.83148220e+01, -6.37050021e+02,  5.96909056e+05, -1.76981714e+05,\n",
       "        5.07887900e+01, -2.14756233e-01, -4.63182464e+04, -4.51869235e+02,\n",
       "       -4.98438960e+03,  1.52399419e+04])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17654814.600524537"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+08, 1.27427499e+08, 1.62377674e+08, 2.06913808e+08,\n",
       "       2.63665090e+08, 3.35981829e+08, 4.28133240e+08, 5.45559478e+08,\n",
       "       6.95192796e+08, 8.85866790e+08, 1.12883789e+09, 1.43844989e+09,\n",
       "       1.83298071e+09, 2.33572147e+09, 2.97635144e+09, 3.79269019e+09,\n",
       "       4.83293024e+09, 6.15848211e+09, 7.84759970e+09, 1.00000000e+10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)\n",
    "l1_penalty_values\n",
    "# as value of l1_penalty(lasso )increases then its removes non _zeroes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `LinearRegression()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an Array with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [372168.45176052 426406.15735175 514597.24156473 ... 386569.29843544\n",
      " 603526.91554221 403691.39251096]\n",
      "predictions [405484.78913389 448446.8587729  519283.27576858 ... 416537.57539109\n",
      " 589885.40580396 430721.56872146]\n",
      "predictions [447938.96446403 476532.77326124 525254.5719367  ... 454725.40108029\n",
      " 572502.37117729 465165.44612565]\n",
      "predictions [502441.14414523 512143.34224633 532721.72948596 ... 503445.01841746\n",
      " 549644.66699466 509264.02427823]\n",
      "predictions [539221.19604764 536301.62726975 537867.73436482 ... 536417.51146992\n",
      " 534468.33589074 539051.39143332]\n",
      "predictions [539368.7011203  536858.20704725 538223.66375022 ... 536884.74009097\n",
      " 535211.20814298 539278.70649548]\n",
      "predictions [539556.66608184 537567.44409357 538677.21758735 ... 537480.12034858\n",
      " 536157.83309283 539568.3704016 ]\n",
      "predictions [539851.59372075 538121.8003995  539092.37245282 ... 538024.3328043\n",
      " 536875.24115554 539878.26906259]\n",
      "predictions [540238.34770277 538758.07162434 539588.64171342 ... 538674.663423\n",
      " 537691.32462832 540261.1752105 ]\n",
      "predictions [540731.17862767 539568.85613027 540221.02521838 ... 539503.36346286\n",
      " 538731.23938392 540749.10293665]\n",
      "predictions [541359.18074746 540602.01854498 541026.85570011 ... 540559.3551943\n",
      " 540056.37674425 541370.85703291]\n",
      "predictions [542159.42813968 541918.55156621 542053.7053257  ... 541904.97904279\n",
      " 541744.96613514 542163.14272504]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "predictions [542532.78900611 542532.78900611 542532.78900611 ... 542532.78900611\n",
      " 542532.78900611 542532.78900611]\n",
      "min_l_error 915082695822165.2 best_l_l1_penalty 100000000.0\n"
     ]
    }
   ],
   "source": [
    "#l-l1_penalty_values=np.logspace(8, 10, num=20)\n",
    "min_l_error=0\n",
    "test1_error=[]\n",
    "best_l_l1_penalty=None\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model1 = Lasso(alpha = l1_penalty)\n",
    "    model1.fit(x_train ,y_train)\n",
    "    predictions=model1.predict(x_train)\n",
    "    print('predictions', predictions)\n",
    "    rss=((predictions-y_train)**2).sum()\n",
    "    test1_error.append(rss)\n",
    "   \n",
    "    if min_l_error is 0 or rss<min_l_error:\n",
    "        min_l_error=rss\n",
    "        best_l_l1_penalty=l1_penalty\n",
    "        \n",
    "print ('min_l_error', min_l_error ,'best_l_l1_penalty', best_l_l1_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzeros` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzeros` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_penalty_min = 297.63\n",
    "l1_penalty_max = 379.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION.*** What values did you find for `l1_penalty_min` and `l1_penalty_max`, respectively? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is reverse technique to get back that l1_penalty value we got as min above\n",
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `LinearRegression()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221282.89856768 335619.31257595 250777.11867825 ...  55044.66070702\n",
      " 623176.89369405 234473.02456077]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221325.24437075 335639.55417776 250921.32392857 ...  55045.75885245\n",
      " 623180.62570733 234644.6390494 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221367.59017184 335659.7957815  251065.52917932 ...  55046.85699656\n",
      " 623184.35772167 234816.25353705]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221409.93597164 335680.03738653 251209.73443037 ...  55047.9551398\n",
      " 623188.08973672 234987.86802403]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221452.2817705  335700.27899248 251353.93968161 ...  55049.0532824\n",
      " 623191.82175228 235159.48251054]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221494.62756867 335720.5205991  251498.144933   ...  55050.15142456\n",
      " 623195.55376822 235331.09699671]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221536.97336633 335740.76220624 251642.35018454 ...  55051.24956636\n",
      " 623199.28578445 235502.71148261]\n",
      "predictions [221579.31916356 335761.00381377 251786.55543614 ...  55052.34770788\n",
      " 623203.01780088 235674.32596829]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221621.66496047 335781.24542164 251930.76068782 ...  55053.44584918\n",
      " 623206.74981752 235845.94045382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221664.01075709 335801.48702981 252074.96593959 ...  55054.5439903\n",
      " 623210.48183431 236017.5549392 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221706.35655348 335821.72863819 252219.17119139 ...  55055.64213125\n",
      " 623214.21385123 236189.16942446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221748.70234967 335841.97024678 252363.37644323 ...  55056.74027209\n",
      " 623217.94586825 236360.78390963]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221791.0481457  335862.21185549 252507.58169512 ...  55057.8384128\n",
      " 623221.67788535 236532.39839471]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221833.3939416  335882.45346436 252651.78694703 ...  55058.93655344\n",
      " 623225.40990254 236704.01287973]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221875.73973739 335902.69507334 252795.99219896 ...  55060.03469398\n",
      " 623229.14191979 236875.62736469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221918.08553307 335922.93668241 252940.19745093 ...  55061.13283447\n",
      " 623232.87393709 237047.2418496 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [221960.43132868 335943.17829159 253084.40270292 ...  55062.23097491\n",
      " 623236.60595444 237218.85633447]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [222002.7771242  335963.41990082 253228.6079549  ...  55063.32911528\n",
      " 623240.33797183 237390.47081929]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [222045.12291966 335983.66151011 253372.81320692 ...  55064.42725562\n",
      " 623244.06998925 237562.08530409]\n",
      "predictions [222087.46871507 336003.90311946 253517.01845894 ...  55065.52539592\n",
      " 623247.8020067  237733.69978885]\n",
      "min_l_error 413207340364635.56 best_l_l1_penalty 297.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "min_l_error=0\n",
    "test2_error=[]\n",
    "best_l_l1_penalty=None\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model2 = Lasso(alpha = l1_penalty)\n",
    "    model2.fit(x_train ,y_train)\n",
    "    predictions=model2.predict(x_train)\n",
    "    print('predictions', predictions)\n",
    "    rss=((predictions-y_train)**2).sum()\n",
    "    test2_error.append(rss)\n",
    "    if min_l_error is 0 or rss<min_l_error:\n",
    "        min_l_error=rss\n",
    "        best_l_l1_penalty=l1_penalty\n",
    "        \n",
    "print ('min_l_error', min_l_error ,'best_l_l1_penalty', best_l_l1_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222087.46871507 336003.90311946 253517.01845894 ...  55065.52539592\n",
      " 623247.8020067  237733.69978885]\n",
      "[ 5.93102241e+03  4.98305673e+04  7.30027235e+02  5.93533704e-01\n",
      " -0.00000000e+00  5.94058083e+05  4.64885791e+04  3.31191386e+04\n",
      "  1.01058235e+05 -1.10996861e+02 -1.31165313e+02 -2.52251436e+03\n",
      "  3.82721142e+01 -5.94397847e+02  5.74036404e+05 -1.45824213e+05\n",
      "  4.98076331e+01 -2.23112567e-01 -4.59982701e+04 -4.64616746e+02\n",
      " -3.26092674e+03  2.33449870e+03]\n",
      "18403005.590543307\n"
     ]
    }
   ],
   "source": [
    "print(model2.predict(x_train) ,model2.coef_,model2.intercept_ ,sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1adbbd6f278>,\n",
       " <matplotlib.lines.Line2D at 0x1adbbd6f668>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzsnXd4lMXah+/ZkgIh1IBAqIIooNIEFEQQqRawoYKCFRXr8VPBIyoKevCoR8EKCggiYgEVlSKgCCi9995CSyABEtK2zPfHvBs2yaZsSEgCz31dubI777wz8664v8w8TWmtEQRBEISixFbcCxAEQRDOf0RsBEEQhCJHxEYQBEEockRsBEEQhCJHxEYQBEEockRsBEEQhCJHxEYQBEEockRsBEEQhCJHxEYQBEEochzFvYBzRZUqVXTdunWLexmCIAililWrVh3TWked7TgXjNjUrVuXlStXFvcyBEEQShVKqX2FMY4cowmCIAhFjoiNIAiCUOSI2AiCIAhFjoiNIAiCUOSI2AiCIAhFjoiNIAgllthTqfQZs4TYxNTiXopwluQpNkqpRkqptX4/p5RSzyqlKiml5iqldli/K1r9lVJqtFJqp1JqvVKqhd9YA6z+O5RSA/zaWyqlNlj3jFZKKas96DkEQTh/GD1/Byv2xjN63o7iXopwlqhgykIrpezAQaAN8AQQr7UeqZQaAlTUWg9WSvUEngJ6Wv1Gaa3bKKUqASuBVoAGVgEttdYJSqnlwDPAUmAmMFprPUsp9d9g5sht7a1atdISZyMIpYNGQ2eR5vZmaw912Ng2okcxrOjCRSm1Smvd6mzHCfYYrTOwS2u9D+gFTLTaJwK9rde9gEnasBSooJSqDnQD5mqt47XWCcBcoLt1LVJrvUQb5ZuUZaxg5hAE4Txg0YuduKVZDcKc5isqzGmjV7MaLBrcqZhXJhSUYMXmbuAb63U1rfVhAOt3Vau9JnDA754Yqy239pgA7QWZQxCE84CqkWGUC3WQ5vYS6rCR5vZSLtRB1XJhxb00oYDkW2yUUiHALcD3eXUN0KYL0F6QOTJ3UmqgUmqlUmplXFxcHkMKglDc+DsEHEtKo1+bOvw4qB392tQhLimtuJcnnAXB5EbrAazWWh+13h9VSlXXWh+2jrBirfYYoJbffdHAIau9Y5b2BVZ7dID+BZkjE1rrscBYMDab/D+qIAjFgb9DwJj7zpgJRvRuWoyrEgqDYI7R7uHMERrADMDnUTYA+Nmvvb/lMdYWOGkdgc0BuiqlKlpeZV2BOda1RKVUW8sLrX+WsYKZQxCEUkijobOoO+Q3Ji/bj9Ywedl+6g75jUZDZxX30oRCIl9io5QqA3QBpvs1jwS6KKV2WNdGWu0zgd3ATuBzYBCA1joeGA6ssH7esNoAHge+sO7ZBcwqyByCIJROxCHg/Cdfx2ha62Sgcpa24xjvtKx9NcYtOtA444HxAdpXAtn2yQWZQxCE0oc4BJz/XDD1bARBKNn4HAL6tq7NlOX7iZOsAecVQQV1lmYkqFMQBCF4iiuoUxAEQRCCRsRGEARBKHJEbARBEIQiR8RGEARBKHJEbARBEIQiR8RGEARBKHJEbARBEIQiR8RGEARBKHJEbARBEIQiR8RGEARBKHJEbARBEIQiR8RGEARBKHJEbARBEIQiR8RGEARBKHJEbARBEIQiR8RGEARBKHLyJTZKqQpKqR+UUluVUluUUlcrpSoppeYqpXZYvytafZVSarRSaqdSar1SqoXfOAOs/juUUgP82lsqpTZY94xWSimrPeg5BEEQhJJHfnc2o4DZWutLgSuBLcAQYL7WuiEw33oP0ANoaP0MBD4FIxzAa0AboDXwmk88rD4D/e7rbrUHNYcgCIJQMslTbJRSkUAHYByA1jpda30C6AVMtLpNBHpbr3sBk7RhKVBBKVUd6AbM1VrHa60TgLlAd+tapNZ6iTY1qidlGSuYOQRBEIQSSH52NvWBOGCCUmqNUuoLpVRZoJrW+jCA9buq1b8mcMDv/hirLbf2mADtFGAOQRAEoQSSH7FxAC2AT7XWzYHTnDnOCoQK0KYL0J4b+bpHKTVQKbVSKbUyLi4ujyEFQRCEoiI/YhMDxGitl1nvf8CIz1Hf0ZX1O9avfy2/+6OBQ3m0RwdopwBzZEJrPVZr3Upr3SoqKiofjyoIgiAUBXmKjdb6CHBAKdXIauoMbAZmAD6PsgHAz9brGUB/y2OsLXDSOgKbA3RVSlW0HAO6AnOsa4lKqbaWF1r/LGMFM4cgCIJQAnHks99TwNdKqRBgN/AARqi+U0o9BOwH7rT6zgR6AjuBZKsvWut4pdRwYIXV7w2tdbz1+nHgSyAcmGX9AIwMZg5BEAShZKKMA9j5T6tWrfTKlSuLexmCIAilCqXUKq11q7MdRzIICIIgCEWOiI0gCIJQ5IjYCIIgCEWOiI0gCIJQ5IjYCIIgCEWOiI0gCIJQ5IjYCIIgCEWOiI0gCIJQ5IjYCIIgCEWOiI0gnOfEnkqlz5glxCamFvdShAsYERtBOM8ZPX8HK/bGM3rejuJeinABk99EnIIgFCOxp1J58ps1fNS3OVXLheXrnkZDZ5Hm9ma8n7xsP5OX7SfUYWPbiB5FtVRBCIjsbAShFFCQ3cmiFztxS7MahDnN/+ZhThu9mtVg0eBORbVMQcgR2dkIQgnmbHYnVSPDKBfqIM3tJdRhI83tpVyoI987I0EoTGRnIwglmLPdnRxLSqNfmzr8OKgd/drUIS4prSiXKwg5IjsbQSjBnO3uZMx9Z8qQjOjdtKiWKQh5ImIjCCUc3+6kb+vaTFm+nzhxYRZKIVKpUxAEQciRc1qpUym1Vym1QSm1Vim10mqrpJSaq5TaYf2uaLUrpdRopdROpdR6pVQLv3EGWP13KKUG+LW3tMbfad2rCjqHIAiCYKE1HNlY3KsAgnMQ6KS1buancEOA+VrrhsB86z1AD6Ch9TMQ+BSMcACvAW2A1sBrPvGw+gz0u697QeYQBEEQAI8L1n8Hn18Pyz4Drzfve4qYs/FG6wVMtF5PBHr7tU/ShqVABaVUdaAbMFdrHa+1TgDmAt2ta5Fa6yXanOlNyjJWMHMIgiBcuKQlwpKP4ZOrIWYF9JkIvT4CW/E7HufXQUADvyulNDBGaz0WqKa1PgygtT6slKpq9a0JHPC7N8Zqy609JkA7BZjjcD6fRxAE4fzh1GGzg9k4DS6/Ex6YCRFV877vHJJfsWmntT5kfdnPVUptzaWvCtCmC9CeG/m6Ryk1EHPMRu3atfMYUhAEoZQRuwX++Qh2/wmtHoTHFkN4heJeVUDytbfSWh+yfscCP2JsLkd9R1fW71irewxQy+/2aOBQHu3RAdopwBxZ1z1Wa91Ka90qKioqP48qCIJQstEa9iyEr+80P9WvgCdXQofnS6zQQD7ERilVVilVzvca6ApsBGYAPo+yAcDP1usZQH/LY6wtcNI6CpsDdFVKVbQcA7oCc6xriUqptpYXWv8sYwUzhyAIwvmJx22OycZ2hF//BY17wVOroc2jEFKmuFeXJ/k5RqsG/Gh5IzuAKVrr2UqpFcB3SqmHgP3AnVb/mUBPYCeQDDwAoLWOV0oNB1ZY/d7QWsdbrx8HvgTCgVnWD8DIYOYQBEE470hLgjWTYenHEFYBrv0/uOxmsNmLe2VBIUGdgiAIJZHEo7B8LKz4Aqo1gWufg4s7gwpksi46CiuoU9LVCIIglCTitsOSD2Hdt1D/OrhnKtS5urhXddaI2AiCIBQ3WsP+JfD3aNjxu7HHPDzPGP/PE0RsBEEQiguvB7b8Av98CIfXwZV3wxPLoUqD4l5ZoSNiIwiCcK5JT4a1X5to/8Qj0OoB6DMJytfM+95SioiNIAjCueL0MWP0X/45aA+0HghtHoOyVYp7ZUVO8SfMEYTziNhTqfQZs4RYv5ozgdqEC4zju0xszPtNYOUEaPcMPLsRrh96QQgNiNgIQqEyev4OVuyNZ/S8Hbm2CRcIB5bD1H7wYUvYMQ+6joBn10P7ZyEssrhXd06ROBtBKAQaDZ1Fmjt/adxDHTa2jehRxCsSig2vF7bNhH9Gw4FlUKWRiZFpejvYncW9uqCROBtBKEEserETI2Zu4fdNR0h1eQlz2rjuEpOP76/tcRlt3ZpcxMs3XlbMqxWKBFcKrPvGJMaM3wU1msNdX0OjniUixX9xI2IjCIVA1cgwyoU6SHN7CXXYSHN7iYoIRUOmtnKhDqqWCyvu5QqFSXK8ifJfNgaSj0Hda+HG96B+x3Me7V+SEbERhELiWFIa/drUoW/r2kxZvp84yyEgUJtwHhC/x7gur5kM7hSzg2n/HNS6qrhXViIRm40gCEIwxKyCf0aZYEwwtpj2/zL5y85DxGYjCIJwrvB6TRqZf0bDvr/BHgItBkC7p6FS/eJeXalAxEYQShGxp1J58ps1fNS3+YVh+0mOhzKVim9+Vyps+A6WfgbHd4AjDK55Cto+AZHVi29dpRARG0EoRfjH7Iy49fLiXk7RcWwnfNTSvB4aB46Qczt/SgKsGAdrvjKvnWVMHZnWA4tX/EoxIjaCUArIGsczedl+Ji/bf/7F7KQkwKhmkHoCGnQx6fXt5/BrKmEfLP0Utv0GHpcRmQ4vQMv7IbTcuVvHeYiIjSCUAgLF8ZxXMTseF3x1K+xdBBEXwZD9EFb+3M1/aK2xxxxaC2gIKQetH4FmfcEReu7WcR4jYiMIpYBAcTznRcyO1jDn37D0E/P+6TXnzuCuNeycZ9L7p8SDxghc20HQ5NZzu6O6AMj3p6mUsgMrgYNa65uUUvWAqUAlYDVwn9Y6XSkVCkwCWgLHgbu01nutMV4CHgI8wNNa6zlWe3dgFGAHvtBaj7Tag55DEM5XcorjKbWsngQznjKv7/8N6rY/N/O602HD97Dic2Pwd6dBSIRJjtmwm0T7FxH5jrNRSj0HtAIiLbH5DpiutZ6qlPoMWKe1/lQpNQi4Qmv9mFLqbuBWrfVdSqnGwDdAa6AGMA+4xBp+O9AFiAFWAPdorTcHO0du65c4G0EoIexdDF/eaF7f8hG0uO/czJtyAlZ9aYSm3EWQlgghZU0gZt32Eu2fA4UVZ5MvCVdKRQM3Al9Y7xVwPfCD1WUi0Nt63ct6j3W9s9W/FzBVa52mtd4D7MQIT2tgp9Z6t9Y6HbOT6VXAOQRBKKkc3wXDyhuhufpJeO3EuRGakzEw52WYeBMcXGkExhEG3f8D9/0I9a4VoTkH5PcY7QPgRcDnjlEZOKG1dlvvYwBfibmawAEArbVbKXXS6l8TWOo3pv89B7K0tyngHMf8F62UGggMBKhdu3Y+H1UQhEIl5QR8dBWcjjX5wvr9cG6yHx/ZYOwx8XugYl0jMCERcPNQqHpp0c8vZCJPsVFK3QTEaq1XKaU6+poDdNV5XMupPdDuKrf+ec1/pkHrscBYMMdoAe4RBKGo8LhgSh/Y9QeEV4IX9xR9jIrWZr4lH4GymzLLXpepHXP7OKhYp2jnF3IkPzubdsAtSqmeQBgQidnpVFBKOaydRzRwyOofA9QCYpRSDqA8EO/X7sP/nkDtxwowhyAIxY3WMPdV40oM8OQqqNKgaOf0uGDjdFg+Bio3gCqXwN6/Tb6ye76FctWKdn4hT/K02WitX9JaR2ut6wJ3A39orfsBfwJ3WN0GAD9br2dY77Gu/6GNF8IM4G6lVKjlZdYQWI5xCGiolKqnlAqx5phh3RPsHIIgFCdrp8DrFYzQ9P8Zhp0sWqFJPWWOysZ2hIOroPbVcGSjKbV8/6/Q5XURmhLC2TiSDwamKqVGAGuAcVb7OOArpdROzG7jbgCt9SbLu2wz4Aae0Fp7AJRSTwJzMK7P47XWmwoyhyAIxcS+f2CClcngpveh1YPBj+FKhbVfG7vKlbk6l8KpQ7DsM9j5B1za09iCdv1pHA4enmucAIQShZQYEASh4MTvgdHNzOvWA6H728HHqaSegpXjza6o6W3Q5lEIrxi479HNZidzfAc07g0nDxihaz0Qrrjr3OdQuwCQEgOCIBQfKSfg02vg1EGo0w7unQ7OILMZnD5m8pBtnAbN7zU7kkAparSGPQuNyCgFl95oovs3TTcu1N3eApu9cJ5LKDJEbIQLkgsuVX9h4U6H7+6D7bMhNBJe2GXsI8FwYj/88xFsnwVXPQyPLYbQiOz9PG7Y/JM5Lqtyidm5bJ8F67+H9s/CzaMlPqYUIXkZhPOK2FOp9BmzhNg8Urn4p+oX8oHWMO91GBFlhGbQUnjpQHBCE7sVfnwMJvQ0cS+DlpkUMVmFJi3J7HjGdoQj683uJfk4rP/WiNMDv0HDLiI0pQyx2Qilmqw7lKE/buDr5fvp17p2wHovWVP1+zjvUvUXJuumwo+Pmtf9pkHDG4K7P2YVLP4fHF5nxKX5fYGP3BKPwLIxpiLmlXdD+VqwcpyJ0bn2Oah+5dk/ixA0hWWzEbERSjU+cVGAN8A/5awiEnsqNcdU/XKcloX9S2F8N/O6+9vGcJ/f3YTWsHuBEZmEvSb/WE7p+uO2GVfp2K0mrb/daSpjVrnEHJdVaVhYTyQUAHEQEC5osu5QsupMTvVezttU/YWJv4dZy/vhxv/l3wDv9cLWX43IpJyADs8bW0vW9DRaw76/jdHf44I2j0Hta0ypgdpXwx3joUKtwHMIpRIRG6FUEqiY2EWRYew9npyniJx3qfoLi5QEYydJ2AvRraH/T/mPV/Gl7f/7AyMkHV6Aprdnrwnj9cCWGWbnUrEOXPs8HFoD89+AS7oZr7ZgHQ6EUoGIjVAqCbRD8Xg197bNW0TG3NdKvNH8cafBDw+aHYkjHP5vm0nBnx/ST5u6NP98ZMomdxxi4l+y7oTST8Oar2HNJKh3Hdz8AWybBb88A5ffYYz+57Iyp3DOEbERSgQF+fIPtEMZ0bspQMbvnMb190YL5EhwQeD1woK3YOE75v2ji6D6Ffm7NyUBln8Byz6FcjVMuv5Lb8oe0JkUZ/KVbZ0JV/SBOyea4M1pD0OLAfDwPAgpU7jPJZRIxEFAKBHk5UVWGOM+3bkhbd6anz09OBegN9q6b+HHgeb13VNMoGQgjm6G8AoQWcO8TzwCSz42Ef9VGsJ1g+GS7tkdB47thCUfwuH1xuhfu63xNNu/xNhnLr/z3JQZEM4a8UYLEhGbkklRuSLnNC5A3cplOHIq9bzyRsttZ5jpWsLaMx5mXd6Aa54O7GF2cDUsfBdST0CvjwENf48yu5LqzYzINOic/d79S+Hv0eA6DVc/BRVqm/uObYdrngq8+xFKNOKNJpwXLHqxE33GLGHv8WQgZy+ygozr70Dgj28u4LzxRsvtWHD0/B0c3buFqu91Nw3N+sFNHwTOI7Z/qTlWO7EfbnjdeIT9MRw2/Wi8xPp9b2wu/iLj9cC2mbDkE7MDuu5Fc33R/yAlHto9CxdfL0GYFzgiNkKxEWj3kery8su6Q4y6u/lZje3vQBBiV6R7NHabwuPV2BTUrlSWEb2bMnvTkdLhjeZON7uDi5pmas76GU5etp/Jy/YT6jC7h3D3SaaFDGNE6GHWe+vRL/1l0ldGsK23n9D4co8tfMfEvHR6CSo3NLEvO3434jLgF6jbPvOaXClmp7PqS5Mf7dbPTK60P0YYB4H2z0HtNkX1iQilDBEbodjw7T5+XXcIr4YQh6JG+XDqVsmfu21eTgX+DgTPTF3DjtgkQh020j1e2jeoTPuGVWjfsIS72WptvLb+fNNE3mcRm0Au4N2aXMTLXesSOftpwrbPwKXttEsdxXFnNbo189s1ag075xmRObLRHHO1ehCWjzW2lQY3wIO/ZxeM08dhxeew5ReTpbn/z6aWzE+DjBfbDcOyrVMQRGyEYsO3+9CQIQItalck5kQKsYmpeR5t5eVRNua+M8fM9aPK0qZ+5dIVW3N4Hcx52RjS+0yCyhdn65LVBdzldtMrYSJVR08A4NOGY/nvxghCHDbSfUeGZUNgy6+WyGwwkf2Ne5tdyl8j4ZIe8MgfULNl5smO7zJBlzErTY6yh+aaPGlf32kqYt4yOuAaBQHEQUAoZh79aiVR5cIyROCvbbHEnEjJ8B4LtHM57/ObnTpsjqJ2/wldR0CTW3O1dzz61UqiIkJ5rNJqov982jTeMQGa3pbp8/1m2R5qH/mdR/R0iN0MF3eGqEZm55SwBy672QRjZs1BFrPSGPlTEkxSzPodYcN3sPxzqNcBrn7ijLeacN4h3mhBImJTssnNe+z2FjU5kJCSITrnbX6z9GSTvmXJR8aI3+nfEBaZ9337lsAEy/jfaahJWukfVOlxwYYfYNF7puhYlUZQqb6J3E86asSsw/Nmd+LD6zW7liUfm4j+a56GqpeaAM41k42rdOtHoWzlwv0MhBKHeKMJ5xW5eY9NW30QgKvfms+u/9x4/uU383rNTmHe62aHcP+v+ctwfHwXfNjCvL78TrjlQ3CGn7nuTjNHY0s+Mn1DyxnDf+IRIzqX3wnX/p/Z3fhwpcL6qSaOplYb6PWRibNZ/gXMeMpkY35wthlLEIIgT7FRSoUBC4FQq/8PWuvXlFL1gKlAJWA1cJ/WOl0pFQpMAloCx4G7tNZ7rbFeAh4CPMDTWus5Vnt3YBRgB77QWo+02oOeQyidZPIes+wLWfFoqDvkN0IdNjo2iqJfmzp0b1KN575bR8yJlHzNU1xpanKcd+/fMOff5hjrhtdNVH1ecShJcTDpFnMUVrWJ8RTz32G4UswOZNWXpjbMyQOANilj4nfDlfeY3Y+/fSU53qTz3/gjNOkN9/0EXrfZ2eycD60eMHacYKtxCoJFfnY2acD1WuskpZQTWKyUmgU8B7yvtZ6qlPoMIyKfWr8TtNYNlFJ3A28DdymlGgN3A02AGsA8pdQl1hwfA12AGGCFUmqG1nqzdW++5yiEz0MoRgJ5j9lU5tIBdSuX4bvHrs74wh764wbiktKIrhCew6iZKa40NdnmPb4L5r1mPLqu7Av9foCIqNwHST8NM56GjT+Y90+tziwYaUlmR7L+WwirALFbyMiHbXNC837Q/l+mcJmPhL0mPubAUmj5ADwyH5JijffbwVXQdhBc/0r2hJqCECRB2WyUUmWAxcDjwG/ARVprt1LqamCY1rqbUmqO9XqJUsoBHAGigCEAWuv/WGPNAYZZQw/TWnez2l+y2kYCccHMoXN5GLHZFB/B7CZ8fcs4bVSKCGW6dYSWX3JyEigqp4K8nq3R0Fkodwp2vJwmnEiSeMrxEwPscwip2tCk76/bLvdJPG5Y9C4s+I95f//MzPeknjTuypt+gmpNTQCmJ81cs4dCi/6mLkz56DP3HFxt7ENJsXD1IOOBdmy7ydocvwfaPW3aJNr/gqewbDb5+peklLIrpdYCscBcYBdwQmvttrrEADWt1zWBAwDW9ZNAZf/2LPfk1F65AHNkXfdApdRKpdTKuLi4/DyqUAQEU4LZ1ze6YhnKOI2Ru0yIDZ8vlk1Br2Y1mPl0e25pVoMwp/knHOa00atZDX4cdE3AstCLXuxEtybVsFkD+fovGtypSJ9t6V02FkQOo41zF/3tc/gr9P8Y4JxPeoeXTOLL3IRGa5PDbHhlIzS9P4PXTpy5Jzke/ngTJtwIaYkmoHL9VCM0jnCzK3lmHdz4rhEarxe2z4GJN5t6M20fN9mWy10E390HswebI7YHZxsHAJst32W2BSEv8rU31lp7gGZKqQrAj0CgXCK+XUUgH02dS3sgwcutf25zZG7QeiwwFszOJsA9QhGSW3R71t1EoL4+ktMzF0krF+qgcY3yAZ0Evli0h+V74nl75lbeu6tZxn1VI8PYHXcarwa7Ovs0NXk+W3I8/D6UinsWMr/iDbycOoGLnYeZ62nJusYv8XznLrlPsPdv+LKned3hBZOLzJe4MinWGP13/WmM/KknjWsygLMsXPWQCdCMqGp9gPEmncyKL6BGc5OqplJ92LsYvroVnGVMtH90y2zLkOzYQmER1EGs1vqEUmoB0BaooJRyWDuLaOCQ1S0GqAXEWEdc5YF4v3Yf/vcEaj9WgDmEEkSO0e0B8p5l7WtXxiEgK1rDlOX7GXHr5ZlsPDd/uDiTQE1bc5Bpaw5mpG3xFwbfuL5xCvXZel5qjrFmvgheF0TWpPPRCZwIrcb+TuP4K/bS3ANKj+2Aj1uD9sJlt0DvT854fp06ZJJc7l8CLQcYl+a5r5hroZEmu3LbJ4yzgNZmHd/fb65fN8TYhcIrwY458PMTJklmt7egavb/HsH8oSAI+SE/3mhRgMsSmnDgBoxB/k/gDoy32ADgZ+uWGdb7Jdb1P7TWWik1A5iilPofxkGgIbAcs0tpaHmeHcQ4EfS17glqjrP6JIRCJxgX5UB9gUwOAjYFXRtX4w2rVo1/hgC7TeEJoE4aWByE6J3Ns9WwnaDqbw/Btt9Mp5AI4wjQ7lkqXPciFULKMiKnAROPwtd3wJH1UOUS6D8DIqubawn7jC3l8Hqza4lZDr/+y1wLKw9tHoc2j0KZSsbdecHbpk4NQKuHTGCoPcSIz9JPzO7m1s8yOwpkIZg/FAQhP+RnZ1MdmKiUsmOOvL7TWv+qlNoMTFVKjQDWAOOs/uOAr5RSOzG7jbsBtNablFLfAZsBN/CEdTyHUupJYA7G9Xm81nqTNdbgYOYQSh7BlGD27/vwxBUcO51O+waV+WOrsbd5NeyKOx1QrBYPzpw9GjJ7rhVFXI5vvd0bR7Hw2/d4bvN4wGUuRkZDpXrQ852AO4cM0hLh1+dMnA3A40ugWmPz+vgukzn5+E6Ts+z4TvjpcXMtpBy0fwZaDzSCkxwP3/WHzdbfYxddAQ/MMkdva6cYt+b6neCeb/JVhfO8i2USih3JICAUKVm9tfLrmfbct2uZviZnT7RAxznt3/6DmISUjCzPtSqGs2jw9UD2tDhxiamZdkYF5vgudk94mPpJqwHQ9hAOUo3ILi8Q2aZ/zmlmPC4jJL4dyL3TTX0YMC7Li94zwZfN74WN00z2ZQBlh86vmh1OaDlTpOzrO0ycDkDUZeYIrnEvCI2A9d+Z160fgfCKQT1akX1mQqlC0tUEiYhN8ZC1AmduFTljT6XmWEnTR26pac7pl6PHzTvDnuIF+5QYAKMPAAAgAElEQVSMpv3eKBZ7L+dt993c3KZxYHuQ1iYO5sdHzfubPjgTyHl4nUmOmX4amt4BW381hn0f3d6Clvcbg/7uBfBV78xjl40yjgEpJ4w4Netrxg6NKPTHFy4cRGyCRMTm3JJbrjN//HcoQ3/ckMnIH6hvmttL1XKh/Pp0+0I50ilQRoHD62Hy7XA6NqNpnbc+w1wDWKMbZltzxg5szyKYeJN5fc1TJo+ZM8wkulz4jmlv1NMkxtw+68wgPf5rYmVsDpMZ4Lfnsq/p2v8zqWb2LoSrHjFpZRyh+f0YBCFHJDeaUKzk9SWd1cAc6lBUiQjjWFIaae7MBue8hKmM006Py6vzUPt6GZkFCssVNyjXXlcq/P6ycSH24w33fXyju5GibRkF2jIZ1GO3wNiO4E41gZK9PzHG/L1/m2DNkLKmdsz22fDL02cG7vmuERlXismbtuzT7Gvq/Kqpqrl7gYmr6fLGmWj/tCQTd7P6KxM8GsC1WRDOFSI2QoHI60s6q4E53eOlTIiddE9mgzMaLqseSbXIUP7aHpcpCafTrnB5NJUjQvh1/SGmrY7JuBasK66/OKLJdlyX53h7FppgSIDqzeDwWqhyCYPLvoGzYi2mZSnQlub2UlPFU/Wb7ia7csW6pshYhTqw6w9Y/D5EVDPlkrfPgZnPn5mr+9vGJnPqoLHH7FmYfT3d3jLj7phnsgPc9MEZ+9DxXUYQN/0ITW+He6ae8WwThGJCxEYIivzGX8SeSmXmhsPc1jyah9rXY8ry/fy+6Ug2z7TR83ewLuYEDaIiMpVwrl+5LB/1a5HRb1qvpmflipst0l9B3UplOHIqNffxUk/Bp+3g5H6o0cLYVQ6vhdvHweV38LZfV1+BtnubVSDl5/+j+ZbZ5sIjfxp34+2zYfqjxkut3nWwfTbenfOxpSaYfl2Gm93JoTUwPIcKoj3fNWK16w8TiFnnGiMyXi/smGvS1hxcaY7SHvtbSgAIJQYRGyEosh6PKQUVwp18/Ujm0sGj5+/gRIqLcKeNxjUiGdG7KU9f34Anv1lDlXIhfL/yQCbR2hGbBIDLipVJcbsz7vNREFfc3DIT+LtJBxxv0f9g/utn3h8yHmf8+5A5+srCmHsuh8UfwJeWh9ndU8yx2ZYZMPMFiLoU6rbDtXUOBzYtp757FzZglPs24ps/xesRO0xqmkD0fNfUkZn5PAxcYMQLjMvztIdh13zz/oZhcMf4/NXBEYRziIiNEBT+x2O+KP+EZBdTlppo/Nx2Pne2jM7YXeRUv8Z3tHX4ZFpGOQHfjikjriWIsgKBMhNoTMyOTUHtSmUZ0bspszcdORMDdHQzfHp19sE6v2oM8Vnxeo1txIqBSew0nHLtHjUxL593gosuN7Vhdi+ACrVwxm2kPjDB3Y333HfynOMHntnQCTZkGTc0Ejq9bAIxfcdsN48yQrP7L1NmwMflfcy1kDJ5fiaCUByI2AhB883y/WhtihL58ImK066oVDaE02nuDEeAdLeXNLc3Y1fh62uzvvj9MwZkxectGXsqlYRkF8N7N2X0vB2Zygrk5qyQU2YCnx2pfYPKtG9YhfYNqxhD/P8aG1sJQN1rYe8i89o/2NKfXX9muCAvqXIHjx3syms7dnPblhtMAbQazeHAcqjZHGI3Qewm1nvrMcT1CKOcH/NA2JzsY1aoA1c9bDzUZg8GlLHjNO8H84bBsPJn+nZ6Gdo9C46QTEMUV90eQcgJcX0W8kVWA/vQnzcyb/PRTLVmOl1ShUplQ5lmBWP6vtBva14Tl1dns7ecTHERXbEMfVvX5ovFu5m18TApfkk3/TMA5OYW7ROtQLE7kDn+ZvCkebTzrOSWB4acicW5t6X5Yv/zTXND/Y7GVnNoNdS+xkTdh1fIPOiRDTChJ6SdYpH3CoakP0Qn+1r62v9go7cuduXhUlsMTdrdbFL5A+m12hNyYHGOn/HB8Euo2fbOM+tQdug63NhlJvWG1BNnOt88CspUMXagnu9krtBJ9vgmQSgoEmcTJCI2Z0fWL6+Xf9zA17nExPiwKejSuBpVIkKZsnw/IXYjQIG+BH0ZABx2hdujqVE+jOOn0/MVr+ND4SXE4QjsUbZtFsweAl3fhMuseJd9/8AEq6+zLDTpjfvASk4lxBHa+n7Kdn0lc02XE/vh+weMET6yJtw9hcTtf3F04XjWuWoRTho1bAkcimpP91PfY0tPMjuc9NMm3UwATtdoxyp3PTrETrY+NCdcP9TKc/ZW5s5X3G12W8oOF3eEFvdncmkuqro9woWLiE2QiNgUjPwGZ2Yla6R/1uj+mPjTnExxo4Gx/VuChm4fLOSaiyvzz67jJCS7qFUxnGmPX5PZ5mLFsfi81lpWTGVTUhnSXG7uD/mDvmWW80LE24wd0IqqznSTusXmIOXXwSRt/h1732+odHErk9xy1BVnFnzdENj6G9Ruy+ENf/Ja4s1UbXX7GUFMjjflm9d9Y973/Q5iN7N17ni2eaOJ5DQhuPnLewX97POpY4uFslWNoT4HkdkS2Y6jVKbjqRmmwRFusjnvnA/Hc6n9U6c99J16Jhu0H7GnUnP02pPjNKEgSFCnUOTEnkoNGAMTEWonKc1DlYgQWtSpyELrmr8QZPXu8k8b07d1LXp9/HeG55nPHTkh2cVvG45k9DuQkELrt+Znsu143enUr1qB125qzN9T36Z76kKecQ9kZMg4EnQEzztfZsPBBBZ/+z69Er9hircL99jnEX5iL4+7XuTiNW5e+eN6U/IYTMbkE/sgYS+vH2rFrYfn8S/XIHbpmrBsP98v28kTzl952m6VYr7xPTh9DOa/AZXqU79WNK4Tih8SmvOCYyrt7Jsy1s/p2ExZBjK47BY4sZ/LDv99pjBU1SbGprPss5z/g/T4r0m8mVO+NSSBppCdkmK/k52NkCO+o7P8/BPxfbGFOW180f8qpq+J4c+tscz5V4dM/8AD7ZTKkUwoLo5RPlN7b9ti6qijrGvwGJdGJDPo9GcsSavLjLBbePDkRxyOO852VZ8H1c+8776DiZ6utFA7eM05iQoksVnXoYd9BQDLvJdyUFfhNrufzeS6Icbm0eV12PUnaUe28IrtKWZsTSLd5ebukEW8ZRtj+l79pPm9e4E5Pks+ZurBKDts/CF/H2jj3rD5p/z1tfCUr82zIcN4pf+N+f6ikASagj9na7+TY7QgEbHJPwU5OlNAiCU497apDZDtH3jdIb9lu686x5kUMpIpnuuZ4DE2hXIkM9w5nptsS7k1/Q0a2/bxlOMnou8YSYepKYyyf8AuXYM66ggXkcAg1zMc0RUZ4pzK7fZFbPNG08gWk20uHwsq3kG7kJ04m94Cze41Lsu12kCHF3j5p40cXPULXzr/C8Af3hY0v6whEcc3sOVUKE0cMdjTE03qmaKkRnOocgl7d22hU/xg+rWuI4Z+ISgKy34nYhMkIjb5x3fuP2fjYdLcmlCHonr5cPbFJ4MOUH87n0x+qDWDp23goBUf01DFMMr5MYmEM8p9G/94m9JCbWe4cwIuHBzQUVRWp4gq66TiveOxnzxAynePcMBbmSvVLv7yXsnLroe43b6QhxyzqKxOYSd3kfzJcw2NKioue+ATU0vmp8dNQsxG3eHgapLG3UKEN5H0crX5JzGKGt4j1LXFEuKrU1PUVG4ASbFsTa3AF+4ezPBcQzrOjMti6BfyS2HZ78RmIxQZZ879jaykuTWHTqTk6zgtK/7lnWdvPEKZEDtAhqg85XqSYY6J7PDW5Bn7NNratvCO+y6+DPkvl+r9fOC5ndMNHyfksw95xf4lITqUKBXPf9x92aurMSP0ZbZ661BVnchlFTDDczUN1CFmetrweuLVLNi5hPJrxsAdX4LNDuO6woFlRAC7vRdRP3E/HdlvygUCv3raUE8doYltX/AfQr5RpkrnTR9QqVIr0mdtxbbpCEilTKEAlDT7nYiNkI1A2+90SzHqVi7D/vjkjPiay9Q+tulaeLFlHQY4IzSRnM6Ik+lsW8V71X5nkPs1TqZE0tK7hw/VR/ztacJ/3PcwI/QVAO5If43d1OKjNc9yvX0NAAmU4z3XndxkX8qr9q8AqGGPz/FZUnQIm3UdDunKvOR6hLJlyzIobSIxi5Mof/+XsGDkGQ8zi/o246QwzdOePzwtuN8xm5vsy/L56QVJWHnwekyRtNYDofLFAFSlYOl5BMGfYCrlFjV5HqMppWoBk4CLAC8wVms9SilVCfgWqAvsBfporROUUgoYBfQEkoH7tdarrbEGAEOtoUdorSda7S2BL4FwYCbwjNZaF2SOnJBjtPzj237PWHso135dbCsZ6fycdmmjSeVM7ZSyIXbKhzupU7ksK3bH8rzjO1rZttHHNYzXoldzT+g/JHYeye/TxnHTVQ0p9+dQ7kl/mfa2DTzhMG7AzTwT6X1JKMN2nan4vdTbmL3eqjSx7eVy2948n2ONtwFpOHnVdT/bdS0qcopRzo9Zpy/GiYfHHL9kv6lcdej8Gm/M2cNdp7/O1fZTYC6+3sTSnDoIV94DLe4zopMFMfQLJYFzZrNRSlUHqmutVyulygGrgN7A/UC81nqkUmoIUFFrPVgp1RN4CiMEbYBRWus2lnCsBFphjv1XAS0t8VgOPAMsxYjNaK31LKXUf4OZI7fnELEJjtzKMkdXDOfmkDU8e/I/THR35S13v4xrZUPstG9YhTH3teLN7xdx7fqXCFdpLPdeymkdRrcKB7ny+rtI/W0IeFycpCyndRgaxcW2wwDclz6Er0JGZprzSNjFJCSnk0gZWtu25bn+bd5afOHpwQ+eDmhsNFF7mBzyHyqqpOydy9UwnmXXPGnKNf/8BLiSs/c7GypdDO2ehp3zIDkB2jxqCqXZ5XBBKNmcM5uN1vowcNh6naiU2gLUBHoBHa1uE4EFwGCrfZI2KrZUKVXBEqyOwFytdbz1AHOB7kqpBUCk1nqJ1T4JI2azgp3DWqtQCKzYa46mapQP49DJzFvvBypvod3RHzjqrMVXad0yXTud7mHOpqPc9NKH/Nf5Oe94+tDFtpKOtnUc1pWIOwX88jRhwFD3A4xwTgAFf3muIFInc9JeMZvQoGykpiRxme1ovta+p2wz3i33bw4kO+mcvJlhrveJVscy9XFrG+n2spTxJppiZkmx8O29QX1G+eL2ceB1m/oy+/4xZQFqtij8eQShhBPUn1VKqbpAc2AZUM335a61PqyUqmp1qwkc8LstxmrLrT0mQDsFmEPE5izJaq/xF5obL69OxL65tD40nbdSe/NC1DKmPXVXJo8Xm4JXo9dyF3N4p9yb/L3Zw4SQdzjgjaKWLY5IlcxBXZkv3D15wvEzAN+7O3CJ7SBR6iRR3pPZF+UIp64rH0JTozk07kW9ecMYmvQULm2nge2Q8cv2I0FHUFEl4fAmQsRFGYk0C51abUyZgkY9oM9XQRUwCzYQr6QE7glCTgS26gZAKRUBTAOe1Vqfyq1rgDZdgPZcl5Ofe5RSA5VSK5VSK+Pi4vIY8sIg9lQqvT/+m1s/+ZtYy1gYeyqVPmOWEJuYyqIXO9GtSTUC/SdwbZrBG2nv0C/5Oe6w/8VrsdfR7q05/L1uqwnoVG6G2SdQK2EJA22v47KXY3vYAIAMoZnhuZr13vq85vyKeG3SrVxnX8+Vtl0B17vNGw2u03k/WEQ1sIea/Gct+lNHHTVC40ciZUkPi8p8lJZ0hELlosvh8juN8DXrB4/Mh86vBF0pM1uxt0LuLwjnmnztbJRSTozQfK21nm41H/UdXVnHZL68HDFALb/bo4FDVnvHLO0LrPboAP0LMkcmtNZjgbFgbDb5edbzndHzd7D2gHETHj1vB8+2KccD45exKSkio8Rz+OEV/Ncxixfdj2bc18W2irEh7/OZ+2bKkkZtdZSHnbPpaVvKdE97Rrru4cOQD/nd04pXk3rQ5vQqhocOzzT3D54OdLStpRKJfOHuwXFdnia2fQHdln/3tKSJbW/+DPTRraHl/dCwi3n/5Y2ZLifqcLbo2jRxHiEktWj+6JhduT/XR+wjJCQUmvWF+p1yTSuTE/mthFrQ/oJQXOS5s7E8v8YBW7TW//O7NAMYYL0eAPzs195fGdoCJ62jsDlAV6VURaVURaArMMe6lqiUamvN1T/LWMHMIeRAo6GzqDvkt0xp+r9ftpOjn93CdSmmyuPkZfu5Ysh3PH/6XZZ5z8RzXG9bzech77HQczkj3XfzmGMGzWy76WlbSiohTHFfz5Qy7/CB+3bGeXoy1DGZb7MIzRpvAzrY1pOsQxnhvpeHHbMY7JwacK0/eDrQ1b6Kmup47g/V7hl45Rg8PBca94Kln8K7DeHY9kzdyqkUWtu2UdYT4IjuLNjgrcsIzwA2eutSkVMkdnqLPknPEVv1mkxC479zRGs4vB4WvA2fd4btv2cac9GLnbilWQ3CnOZ/zTCnjV7NarBocKeAawi2vyAUF/nZ2bQD7gM2KKXWWm3/BkYC3ymlHgL2A3da12ZivMR2YtySHwDQWscrpYYDK6x+b/icBYDHOeP6PMv6Idg5hJxZ9GInXvhhHX9tP2Mof8kxhb26GpWU71RUM9w5gUokMtt7FQCdbGsYH/Iu+71RDHQ9R7Q6xgDH3Iwxwkjnbefn3Jv8bw5Tib1hfbPNvctbnUhOs85bnyrqFK86vwq4xo3eutjxcod9Ye4PU70ZPDDLVKX0uEj86yPK/flycB/I2dDjHeYsWckVqat45IqafJH8KftTQohaozOOsvxTy3w8dxPh+/5kz5efUdW10gSRNr8P+kyE8tGZhg42EK+kBe4JQk7kxxttMYFtJACdA/TXwBM5jDUeGB+gfSXQNED78WDnEAJTNTKMQyfOGPu725ZTTSXwnvvODEP9rbbFNFF7me29itOE09G2hgkh75CmHfRJf5Uq6hSLQ5/JGGOapz0dbOu52HaYWaFDqKAC21Y82DhBBF3sOYdCHdSVSSWEVrbtOfbxke4sR4gzHDb8ANMeInui/SKi/b8gYS9smk63Gx6Byz4Gu5Pvhv7Edd7ldLAvZY5+iMnLYOayjVxvX0Nn22petK3H5tTMjG3N+577WWtrzNbrbsxxmmAD8UpS4J4g5ITkRrsAyHquH61iGeN8n3vSX8aOl1HOj3nZ/SCfOT9gq67NT552lAuBTzAuyJObjGPy6jimhgzPJCjjnPfQJW0etW3Z7SCndDiRKqVInmdhVF86xE0pkrFzpclt0HYQ1LrKRP3vXQTrvsW7dSarQlsx9cRlRHni6OpYTTO1AxuavWGXMSG5HdPT2+JyRkhtGaHUUVhxNvn2RhNKL/7n+k7cfOD8hJddD+FyRpJEGTrYN/Ch80OGuQbQRO3FiTtDaP7lGsT8TQf4MeTVDKHZ4q3FFm8tHnJ9k6PQxOiq2drzwxDXw3n2OddC86n7Zq5O/ZBG6/pASFmY+yq83xSm3AVHN2Crfy010/fxGNN5xDGTaGL5J6oPPL6Ezxt9ziTX9aQ7IorkiCuTPUgQSjASvnyekinuwjrXT3V5edkxldmeq1irG4DLyysOkxesmW03tVQsFVUi40PeBcyXbLIO5Qv9OnZldsCxugLPup5gTuiQHOeOVCk0VsElrHRpOzO81zDS+UUBn7hoaJI6jjKkcYv9b263L4ZP/Z6rfC1T9MyVTJq24alQl+Q2A/ji6CUcOe2hfbXGHEtaWaRHXP4uz1KCQCjJiNicp2T9EjqWlMbQhntpFRfPrSeMEb+3bTE32ZcAMCj9aT4JGZ1x/1xPC2J0FGNC3s807vOuR3MVmoLwsutB3nSO53b7okId92z5zH0zHztH09G+LlP76TbPULZiDTi8Fo5ugqa3Ua/HfzNiaV63+sWeSiUh2cXw3k2pWi6MEb2zmSULjLg8C6UNsdmcJ/h2MmsPnCA9QMGkuo54FtQcw9DIN5m8IYkmtr2MdnyIDS/1AqSBGeO+kUcdmYudxenyRKnCdR8ukURfBTErAl46piM5ripTu2lbwlvfb7IE5BBPc7YVEnOjsGqVCEJeSD0bIRO+ncytzWri1prf1h3Co009mVuuqMrbpz+CLu+w8OuTRKtY3nWOIVGX4bQOox7ZxSar0AAXhtBANqE5rCsRThrbdC1+8HRgpqcNp1eGE7o2gW0jsgvNudh1iMuzUNoQsSllZM2BlfWLLWumZo+GhptG84GuxSefHmeU82N6hf7Db57W3Ghfnud8adpBqHIX+nOUdA7qyhzXkYTi4g9vc773XMduXSNTnzS3l0ZDZ2UTkEUvdspx11GYiMuzUJoQsSlFxJ5K5aYPFxObmMboeTt4unND7qm8k2OVmjNvZyKpLi8KCHEo3B6NR0MH2zqa2vcxIO0F7rIvoJf9H4B8CQ1wwQnNP57GlFFpHNGV+M5zHX95r8SDPWDfXs1qBBSQc7Xr8K9tU5j2IEEoCkRsSjrpp+G3/6PpqhtJcp/xVPcdzawIfYcKJ0/zrHcQs2iLFwix20j3eKhKAkMcU7kvbQiNVAxvOz8vvucowZzQZVnhbUQ1lcCfujk/e64l1huZcT26YjiHTqRkVCf1kZuAyK5DEDIjYlPSWf0VO9Yuoq+Gsdyc6VIVTmbYUT52jqaepzWg6Oz6i1m6Ne87P2G4+15SCWF2IXuQnQ/sUrXweGGlpyE/qU5UanA1K/YlcPy0C7sCr4YGVSNISnPj1SaNhgZubHoRFSNCcxUQ2XUIQmZEbEoyHhes+YoKg37njjE3MSP5Go5QOeNykyylke+x/8lVtq3Y0NSzHWG591KWeBuzN8xU0vzF05ab7UvP5ROUGFJtZQjzWtU3QyKgZguWprVn+O6GeB3huNxeGhxL5vhpF2FOG18MaMXsjUeJS0xl8yGTO67H5dWpVDaEuMRUERBBCBJxfS7JrP2GT6fP4e30O+lgW0cf+wKedJncZBVIZG3Yo9lume25iq89nRlo/5X/cz3O8jCTQu7frod4yznunC6/uPnD0wwPtoycbKnayVjPjUz3XIvXHoYuV4MDCSkZO5b8IrEswoWEuD6f73i9sOwz7hg0mTVzj/L7piu52/4n7W0bOKnL8kvo0IC3LfNeykuOb5jiuT5DaD5z33zBCM1fniuY7b2KRuoA9ztM+v4l3sbM9bbCoxXtHFuYbn+NeZ6WvJhgxDovoQl1KNLcusi8ygThQkDEpoThc21+9/IYNp+sRYuyUeyJ200ZUhnuuo8lYU9xQpcNeO+brr685vyKOF2eG2zmr/kd3po8Yv/1XD5CsfCjpx2pOoR7HH9ynX09ANu9NYmhGjWI41XHpIy+79Qbz1HnRYRtOUmqy4hIVEQoBxIyJw6NCLWTlOYhza0llkUQzhIRmxLGuJ/nsXwPnDj6P0akPErMm/MBzd6wB5nmaQ+QYyr/l50mQWWUOpmRYiWecjRU5/9R6a32vzO93+Wtjhcb19vOlDXw2kM5FFKPOw69jd3uYL77abSjfEacUtbjtKQ0T8brNLcXu1LEJaUV5WMIwnmLiE0JodHQWUR7DjA/9AUqOm5mp6sSMToKgFrKVMPuYQucQsWfbd7ojFLKcz0t6WJfVXSLLoGc0GVx4eBiW+bCrad1KGVrtiS68S1w6U08+stRbrwkLMM1ecqyfTkep4XYFeXCnIy6uxmj/9hJbGJqoexusgboCsL5jDgIlAS8Xq59ZQpv2j6jg30DADenjWCDrk8n2xqed3xHEuG0sW3Nduvfnia0s2861ysuNSz0XM5sb2t+97Qi0VExR8O+L9eYL82PD5vlAg3QsGoEO+OSCi3XWVHmThOEwqKwHAREbEoC676FHwcyw34DHd3/EKmS+cB9GwrNlWo3/3Y9xKiQj7gqH1UsBVipL+Mb13XM87bgJBHYFdx0ZY0ck1T6dhjRFcKZvuZgJoHJjYJ6pWVNMXS24wlCUXLOiqcppcYrpWKVUhv92ioppeYqpXZYvyta7UopNVoptVMptV4p1cLvngFW/x1KqQF+7S2VUhuse0YrZVLoFmSOUonXA3+9DcC8lEvZrk1N+mcd06ml4njc9QwjQz4XockH39Z4kceif+YR+xusrtSDk0QAJj9cboZ9XxLTFXvjubdtHX596lrubVuHjpdU4ZZmNQh1ZP7fJNSh6NWsBosGdyrQOv2L2QGEOW1nNZ4glAbyU6nzS6B7lrYhwHytdUNgvvUeoAfQ0PoZCHwKRjiA14A2QGvgNZ94WH0G+t3XvSBzlFo2/Qjxu5jg7sYgx89cZhUd2+etSiUSGV/2E5qpXbkO8aar77lYaYlkY/hVjGg6i3ppU9gQdQtVKlcmIdnFnmOZnSgmL9tPo6GzMrU1GjqLukN+Y/Ky/WgNBxJSmLx0H7d+8jcjejflywfbUC7UQbrHi91K7mxTkO7RZ+WVJhmbhQuRPB0EtNYLlVJ1szT3AjparycCC4DBVvskbc7mliqlKiilqlt952qt4wGUUnOB7kqpBUCk1nqJ1T4J6A3MCnYOrXVmi3BpwOuBnwYRFxLNG6n3sSfsXgDWe+txhW0PdYgFD8ZNKhd8XmgXEkO9A/k2vT2uVAesTACMoAQip/iYrNmZbQq6Nq7GG37ZAXw5znbFJXI8KZ0qEaHUj4o461xnkjtNuNAoqDdaNd+Xu9b6sFLKV3C+JnDAr1+M1ZZbe0yA9oLMUbRiM6YDHF4HTyyHqEYFHmbzoZPcNWYpn97bgm+//IAPnWk8mvwwE5zvADDB3Y3xnu4sCv1X3mN569DYFlz55dLIXE9L6qgjpBDKWPdNzPK2xmttym0KQhy2DLFQkMnAH5LLzqFqZBgOpcy9GDvNgu1xmfr45zjz2Xae7tzgrHchkjtNuNDIzzFaMAT6G1wXoL0gc2TvqNRApdRKpdTKuLi4QF3yz8C/oOnt8HFr+OQacKfn67bYU6n0GbOE2MRUYk+lcusn/5CY5uaxySv40PkRm3Vdhjon09G+jojzHDAAABHfSURBVBXeS3jAMSeg0GzzRmdruxCEZrqnPeVVEiPd99ArfTi/edtmCA0YgUh1meMoryajYBxA+TAHPw1qR782dXKMj/HV//GZ61NdXlq/OT/bkRtkLrUtCEJwFHRnc9R3dGUdk8Va7TFALb9+0cAhq71jlvYFVnt0gP4FmSMbWuuxwFgw3mjBPGA2lII7xkP3t+HdBjAiCroMh3ZP53xPzEqmLDrCir2K1m/OB6C9bQNRthM09+wEBzRWezPk8w9PixwdAXyxMxcC49w96GBbz3Ei+cHTgX+8TQj0N4YCLiofRuPq5fhn1/GMdt/O5mSqm56jFwX08srJI8yHf2G0c1F5UxDOdwq6s5kB+DzKBgA/+7X3tzzG2gInraOwOUBXpVRFyzGgKzDHupaolGpreaH1zzJWMHOcGyKiYNhJuOdbmPsKDCsPh9dn69Zo6Cz+/ekU7t36OA39Tv2qq+O8H/Ip/R1zM/U/pcsw2Dm1yJdfGnjIMYvBrke4O/0V/vE2JSejlQYOn0xl/tY4UlxGDKIrhufLyyurR5g/dltmb7OS5j3mv1sWhNJCflyfvwGWAI2UUjFKqYeAkUAXpdQOoIv1HmAmsBvYCXwODAKwHAOGAyusnzd8zgLA48AX1j27MM4BBDvHOadR9/9v797DoyrvBI5/fzOTKyQSkqAhiQaogkhV8IJUtIjFCyKItlvo6hZtvQO1rkUtrehTn1ptuyIrKlrtKhXUIspKrdZVuw/suiA2Kje5qAEiahIxEHKfmXf/mHcmM8lMLjBnMkN+n+eZJ2fec2bmN+9kzm/OezkH7voaTpkJS86BRWOg+WBo9Zp555Ex5Cz2mnwWpj3CCbKHCa73ucH9Smib7f7i0HKuNCQ0/GQ2t2U2e0whY2Urg6np0WMrv26kySaeaH01wR01QmhEmCssl7kFfH6DxyXMXlYeOFtAko0e0+Y8lYp0Umc8HKyC3x0fWJ7wc6pGz+XM+95C8PNq+s+5uXUui9MWcaJrNwdMNrnSwKyWeWz0D+G9zBudiSmF7TfZbDclbPOXstx3PptNGaV5WeRmpbG/sZXKdifMjMbjghlnHkd1XVNEZ3z4rP3qg80U5gROWXP90sD/xpKrTmfZ+t3897YqKmsbQ7P7r1+6IbRtcPRY+PMmgk4GVb1BzyDQQwk5g8C212D59wG4vPlu/mFO4Om033B767WsyLiHEmn7lb7JX0Y2TQx1feFsTClmVsvP+Lv/VNo3nblo68TvSll+Ni/cMC7iyKO7O+pk3qEHT6kTHKodPqRb5+gopyTsDAKq+4YvNQxrWgrAyoy7qcj8AWNcO/i/zDmUSA2rfWND245yVWiisbzGxS9bZzGrZR6lUk0GrR226W6igUAzGIaIfo3u9rskW/9MuGRrzlOqJ/Ssz3HS9ovYzaTmB3gjYx4AOdLW5DPFva6XoktuHvHzq7T/CN1/zXcm1aR367Fl+dmU5WdTMrBfRBNXeL/GvdO/GXVH/U7YCLagZN+h62RQlaq0Ge1wVayF8mc5mFPGQ29X4MfFaNcOTSzd8Ih3Kou906gnq9snvwxKdwstPkNpXhZrbp8YKu+sGWzC8MJQv8stz5WzveogV47teMblZOifUSpZaJ9NDzmSbJoOwPIZsOt/ut5WsdI3nke9U9lhOk5Q7ak0t/D9M46lcl8DDa2+0DVhuurXSOY+GaWSkfbZJIOMHDA96U3oW57wTmar/1hGNj1FWdMybm29KS6JBgLDB+69bBQleVkRw4C7agYL9skEzzLgFpKmT0apI5n22RyGqrpm1lcXMqW3A0kilaaAdf4RXOFeSwMZPOi9ggbi299Rlp/N3tpGyu74S6gsfFb/hOGFMfs1znng7YgjG5+BVe/v5bVNX+iRjVIO0mRziLZU1lD3+CVMiXL1zL5sTsscys3xDJdKHvR+L67PLQTOGuDzG9bePjFmcxkGZi8vpyAnvcNJLtfMO4+pi9dSXdeCz29wu4RBORmsmn12XGNVSkXSZNNDVQeaGPvrNzlTtvL79J7Nbj/SPOSdzlPei2kmjVY8+HCH1jWRTibNNJERt9czwJVnBSZqdtZc9ouXNkaMRAs3KDeT80cczbL1gaOgFp+f80cMSprRZkodqTTZ9NDKB37Mp5mvdL3hEW6jv4yJrnImppfTioeDJosGMqkng3qTRSG1FEote8zRcXm9fuluTi45KuJIpf0w4GXrdkVc0ybWCTN1+LBSiaej0bopOIrpJvfLzEt7IY6RpY7XfadzfeutHcrT8NKPRvrRRD9poh9NZEoL6/0jIo52wg3MTqO2sbXbw52PH9SfN279dqfb6Ax7peIvXqPR9MimG6qrq/i1PMxx6VWcHuMSAEeycv83WOsfxSZ/WdT1rXioJYdactquLNRJEgnOjRl//1tUft0Y6ouJJifDQ9GATGobOp5VoL1kn5CpVF+myaYLW/bu57LF6xnqn4IXF/+e9jAnuqJffvhI8E/Nv2S9ObHrDXvI7YJjcjPZV9/CyMG5AJw0OJcJwweFToS5r76F+hZfaIJntAmXXdEmMqWSkzajdSJ8AuAjaQu5wLUBjxyZ82q+MHnkcRAPXj4nn13+o9llBrHHHM1WU8rf/aMP6/m7kzh05r5SyUeb0RwWPocD4ObWuXyaeWUvReOMVb5vUWeyeM9/Ai/5zwEM/WkkXw6Qz4HAXzlAsXQ8h1gswaMSjwvGDS1g974GquqaYl6WOVx4Ymk/ZFkpldo02cTw6tzxTF60NnR/pBw5TWfXtNzGW/4xUdYIB8nmoMlmF8dE7Ugpzcviy7pmyvKzyUpzs3nvflwuIS87nfpmLyeXDGBoYX89KlFKRdBkE8PIwUcxJD+b3V/V8XHmVb0dziFrNW5Obn6CRjL5Y9r9LPZOY4MZ0a3HluZlcXLJAAA+rKxl5OBcTSBKqUOiyaYT9S0+sjMyOLf5QTJoxY2fca7NLEhb2tuhdanSFFAiNfhwsTJ9AXvMIIbJXspN4IqiHhcIQrrHRf8MD183tOA3gU77xlYftQ2tEWdTVkqpw5GyyUZELgIeAtzAH4wxv4n3a6yf/x2uX7qB/90Jdc1eAMazEYAak0uBHIj3S3bpRd85XOFeE1G2xX8cI127mN0yhwNks8Z/Mle413BZ+ruMX/AmC5duYHjGV5wwTJhZWaxNXEqphEvJ0Wgi4ga2A5OASuBdYKYxZkusxxzuaLSgNLz8zPM813n+EuNRzqkxuTSaDG70/pTj3DXMcb3IqoIfUVd6PldvvZZht70NaXZOid8Hfi944ne6GKVU39PXR6OdCew0xnwCICLPAdOAmMnmUKyZd17EjPTzXOX8q+fPvOE7jY/9RQxzfR7Plwt5zHspY9w7yDX13Jc+h9yyMbD7HVpKxrHku8NYnT0wsOHBGxnxyk/AUwEFWeBtaks2LnfgppRSSSBVk00xsCfsfiUwNt4vEpyRXuzbw4L0P3G2fIhbDKNcFQB87C9iqW8Sd6c9E/G4l3xnM93dgwuqXboIdr8DLfVw6UPcEEwmwNOhpTM6Pq7/IJixDMr/BBtX6LV1lFJJK1WTjUQp69AeKCLXAdcBHHvssYf0QjV1TSwqXE1RyWju2/5tis0XnHP5zVz9yj4AHp95Eo+uPRfPzr9xrf8Fat0FTKeLRDN7A+R/Axq/hoo18MotMOkeGH0VSLS31gkRGHMVfPN7bUc1SimVZFK1z2YccLcx5kJ7/04AY8x9sR7jyGWhAaq2wn/OhUEnwpaXoWl/x22KTgGfN7DN9CXgbpfjWxogPTv+sSml1GHq63027wLHi8gQ4DNgBvCDhEbg98E7D8Nb90J6f8joD+NvhXefhBGToV8BrF0I4obSs2DifMg8KvpzaaJRSh3hUjLZGGO8IjIbeJ3A0OenjDGbExgAPDMNmmrh/Ltg1Hchtwj8fjhlJvzXAlj3GBSfBpf8Gww+NWGhKaVUMkrJZANgjHkVeLVXXlwErngSctpdGOzLTbDiaqivDiSZ02bpiDCllCKFk02vC080xsD6J+Bvv4BRl8OkX0H/wt6LTSmlkowmm8PVsA9WzYavdsJVK6FsfG9HpJRSScfV2wGktOrt8OQFUHoG3LBWE41SSsWgRzaHo18B/MsqOKq4tyNRSqmkpsnmcITN9FdKKRWbNqMppZRynCYbpZRSjtNko5RSynGabJRSSjlOk41SSinHabJRSinlOE02SimlHKfJRimllONS8uJph0JEqoFdMVYXADUJDCdeNO7EStW4IXVj17gTK1rcxxljDvvMwn0m2XRGRDbE40p0iaZxJ1aqxg2pG7vGnVhOxq3NaEoppRynyUYppZTjNNkEPN7bARwijTuxUjVuSN3YNe7Ecixu7bNRSinlOD2yUUop5bg+nWxE5CIR2SYiO0XkjiSIp1RE3haRrSKyWUR+YssHisgbIrLD/s2z5SIii2z8H4rImLDn+qHdfoeI/DBB8btFpFxEVtv7Q0RknY3heRFJt+UZ9v5Ou74s7DnutOXbROTCBMQ8QERWiMhHtt7HpVB9/9T+n2wSkeUikpmMdS4iT4lIlYhsCiuLWx2LyGkistE+ZpGIiINx/9b+r3woIi+JyICwdVHrMdZ+JtZn5VTsYetuExEjIgX2fmLq3BjTJ2+AG/gYGAqkAx8AI3s5piJgjF3OAbYDI4EHgDts+R3A/XZ5MvBXQICzgHW2fCDwif2bZ5fzEhD/rcAyYLW9/wIwwy4/Btxol28CHrPLM4Dn7fJI+zlkAEPs5+N2OOangR/b5XRgQCrUN1AMfApkhdX1rGSsc+BcYAywKawsbnUMrAfG2cf8FbjYwbgvADx2+f6wuKPWI53sZ2J9Vk7FbstLgdcJzDksSGSdO/ZlSPabrajXw+7fCdzZ23G1i3EVMAnYBhTZsiJgm11eAswM236bXT8TWBJWHrGdQ7GWAG8CE4HV9p+wJuyLGapv+88+zi577HbS/jMI386hmHMJ7LClXXkq1HcxsMfuCDy2zi9M1joHyojcacelju26j8LKI7aLd9zt1k0HnrXLUeuRGPuZzr4fTsYOrABOASpoSzYJqfO+3IwW/LIGVdqypGCbOUYD64CjjTGfA9i/g+xmsd5Db7y3hcA8wG/v5wO1xhhvlBhC8dn1++32iY57KFAN/FECzX9/EJF+pEB9G2M+A34H7AY+J1CH75H8dR4UrzoutsvtyxPhGgK/6qHncXf2/XCEiEwFPjPGfNBuVULqvC8nm2htjEkxNE9E+gMvArcYYw50tmmUMtNJuSNEZApQZYx5L7y4kxiSIm4Cv/DHAI8aY0YD9QSadGJJlrixfRzTCDTZDAb6ARd3EkfSxN6FnsbZK/GLyHzACzwbLIoRR1LELSLZwHzgrmirY8QS19j7crKpJNB+GVQC7O2lWEJEJI1AonnWGLPSFn8pIkV2fRFQZctjvYdEv7ezgakiUgE8R6ApbSEwQEQ8UWIIxWfXHwXs64W4K4FKY8w6e38FgeST7PUN8B3gU2NMtTGmFVgJfIvkr/OgeNVxpV1uX+4Y21E+BfhnY9uRuogvWnkNsT8rJwwj8MPkA/s9LQH+ISLHHELsh1bn8W6bTZUbgV+1n9gPINhxd1IvxyTAM8DCduW/JbIz9QG7fAmRHXvrbflAAn0Refb2KTAwQe9hAm0DBP5MZAfoTXb5ZiI7q1+wyycR2cn6Cc4PEFgDDLfLd9u6Tvr6BsYCm4FsG8/TwJxkrXM69tnErY6Bd+22wc7qyQ7GfRGwBShst13UeqST/Uysz8qp2Nutq6CtzyYhde7YlyEVbgRGYWwnMFpkfhLEM57A4eiHwPv2NplA++6bwA77N/iBC7DYxr8ROD3sua4Bdtrb1Ql8DxNoSzZDCYxa2Wm/WBm2PNPe32nXDw17/Hz7frYRp1FFXcR7KrDB1vnL9kuVEvUN3AN8BGwCltodXdLVObCcQL9SK4FfxT+KZx0Dp9s6+Bh4mHYDPuIc904C/RjB7+djXdUjMfYzsT4rp2Jvt76CtmSTkDrXMwgopZRyXF/us1FKKZUgmmyUUko5TpONUkopx2myUUop5ThNNkoppRynyUYppZTjNNkopZRynCYbpZRSjvt/wJ3wbTi8WqgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(x_train['sqft_living'],y_train ,color = 'r')\n",
    "plt.plot(x_train['sqft_living'],y_train ,'*',x_train['sqft_living'] ,model2.predict(x_train) ,'-', linewidth =.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386788462905435.6\n",
      "[ 9.02651204e+03  5.01782356e+04  7.31363011e+02  5.89681397e-01\n",
      " -0.00000000e+00  6.06522280e+05  4.61141538e+04  3.33316772e+04\n",
      "  1.00836318e+05 -1.10963200e+02 -1.31640826e+02 -2.51029401e+03\n",
      "  3.82872950e+01 -6.04975194e+02  5.79731876e+05 -1.53734893e+05\n",
      "  4.99618863e+01 -2.22139382e-01 -4.61658754e+04 -4.58167859e+02\n",
      " -3.63801550e+03  2.29006121e+03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srikanth\\AppData\\Local\\conda\\conda\\envs\\SRI\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#here max_penalty we got is taken to get back first l1_penalty value\n",
    "model3 =Lasso(alpha=297.16)\n",
    "model3.fit(x_train,y_train)\n",
    "price_predicted = model3.predict(x_test)\n",
    "RSS = ((price_predicted-y_test)**2).sum()\n",
    "print (RSS)\n",
    "print (model3.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
